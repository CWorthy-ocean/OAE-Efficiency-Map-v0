{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6996cb-5645-4315-a817-e49253051f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.image import imread\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cmocean\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import pop_tools\n",
    "\n",
    "import util\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "import random\n",
    "import importlib\n",
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29990b3b-4fcc-46f7-aa00-874c1dbad5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'POP_gx1v7'\n",
    "grid = pop_tools.get_grid(grid_name)\n",
    "tlong = grid.TLONG.values\n",
    "tlat = grid.TLAT.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945eb439-a932-4236-ada9-776e15c4c4da",
   "metadata": {},
   "source": [
    "# Fig. 5\n",
    "Decomposition of gas exchange timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec818e-08a3-45cc-986e-9649ce1aaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_curves_global = xr.open_dataset('./data/curves_Eta_fracExcessALKsurf.nc', decode_times=False)\n",
    "all_curves_global_tau_FG_CO2 = xr.open_dataset('./data/curves_tau_decomposition_noTau.nc', decode_times=False)\n",
    "\n",
    "poly_ind = [0, 126, 142, 129]\n",
    "season = [0,1,2,3]\n",
    "\n",
    "def no_nans(array):\n",
    "    return array[~np.isnan(array)]\n",
    "\n",
    "# extract all tau files for Atlantic\n",
    "tau_curves = []\n",
    "for p in poly_ind:\n",
    "    l_tau = []\n",
    "    for s in season:\n",
    "        res = all_curves_global_tau_FG_CO2.isel(region=1, polygon=p, season=s)\n",
    "        \n",
    "        res['tau_gas_approxi_weight_1'] = res.mld_weight_1 * res.dDICdCO2_approxi_weight_1 / res.piston_weight_1/86400 \n",
    "        res = res.compute()\n",
    "        \n",
    "        # Add effective mld using the dilution curves, and effective tau using effective mld\n",
    "        res['mld_effective'] = 1000 / all_curves_global.isel(region=1, polygon=p, season=s).frac_ALK_excess_surf  # top layer is 10,00 cm\n",
    "        res = res.compute()\n",
    "        \n",
    "        res['tau_gas_approxi_weight_1_effectiveMLD'] = res.mld_effective * res.dDICdCO2_approxi_weight_1 / res.piston_weight_1/86400\n",
    "        res = res.compute()\n",
    "        \n",
    "        res['tau_gas_approxi_weight_1'].attrs['units']='days'\n",
    "        res['mld_effective'].attrs['units']='cm'\n",
    "        res['tau_gas_approxi_weight_1_effectiveMLD'].attrs['units']='days'\n",
    "\n",
    "        l_tau.append(res)\n",
    "    tau_curves.append(l_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef56ef1-60f0-4282-8adc-aae2a821e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "nrow = 4\n",
    "ncol = 4\n",
    "\n",
    "fig = plt.figure(figsize=(16,14))\n",
    "gs = gridspec.GridSpec(nrow, ncol, width_ratios=[1, 1, 1, 1])\n",
    "\n",
    "colors = ['blue', 'cyan', 'red', 'orange']\n",
    "labels = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "lon_mins = [-80, -80, -80, -80]\n",
    "lon_maxs = [25, 25, 30, 30]\n",
    "lat_mins = [0, 0, 0, -40]\n",
    "lat_maxs = [80, 80, 80, 40]\n",
    "central_longitudes = [0, 0, 0, 0]\n",
    "\n",
    "reg = ['Atlantic', 'Atlantic', 'Atlantic', 'Atlantic']\n",
    "polys = [0, 126, 142, 129]\n",
    "\n",
    "\n",
    "#text_position = [750,95,125,39.5]\n",
    "text_position = [870,280,140,43]\n",
    "text_position_1 = [870,110,140,43]\n",
    "ll = ['a', 'b', 'c', 'd']\n",
    "region_names = ['Labrador Sea', 'Subpol. N. Atlantic', 'Subtrop. N. Atlantic', 'Equat. Atlantic']\n",
    "\n",
    "for i in range(nrow): # polygon\n",
    "    \n",
    "    surf_dil = all_curves_global.sel(region=reg[i], polygon=polys[i])  # surface dilution curves for a polygon, with 4 seasons\n",
    "    tau_comp = tau_curves[i] # this polygon 4 season\n",
    "    #tau_comp = all_curves_global_tau_FG_CO2.sel(region=reg[i], polygon=polys[i]) # tau gax componets for a region\n",
    "    \n",
    "    for j in range(ncol): # season\n",
    "\n",
    "        ################ tau_gas_effective_MLD\n",
    "        if j == 0:\n",
    "            ax = fig.add_subplot(nrow, ncol, i*ncol+j+1)\n",
    "            ax.text(-5, text_position[i], f' {ll[i]}, i', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            tarray = np.arange(0, 180, 1)/12\n",
    "            \n",
    "            for k in range(4):\n",
    "                ax.plot(tarray, no_nans(tau_comp[k].tau_gas_approxi_weight_1_effectiveMLD.values/30), linewidth=1.5, color=colors[k], alpha=0.1)\n",
    "                ind_not_nan = ~np.isnan(tau_comp[k].tau_gas_approxi_weight_1_effectiveMLD.values)\n",
    "                ax.plot(tarray, tau_comp[k].tau_gas_approxi_weight_1_effectiveMLD.rolling(time=12, min_periods=12, center=True).mean().values[ind_not_nan]/30, linewidth=2.5, color=colors[k], label=labels[k], alpha=0.6)\n",
    "\n",
    "                #ax.set_ylim(7, 26)\n",
    "                ax.set_ylabel('τ (months)')\n",
    "                ax.text(-0.5, 0.5, f'{region_names[i]}', ha='center', va='center', rotation=90, transform=ax.transAxes, fontsize=17)  \n",
    "                #ax.text(-8, text_position[i]/3, f'{region_names[i]}', rotation=90)\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Time since release (years)')\n",
    "                custom_x_ticks = [0, 1, 2, 4, 8, 15]\n",
    "                custom_x_labels  = [str(num) for num in custom_x_ticks]\n",
    "                ax.set_xticks(custom_x_ticks)\n",
    "                ax.set_xticklabels(custom_x_labels);\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # add vertical lines\n",
    "            years_highlight = [1, 2, 8]\n",
    "            for p in range(len(years_highlight)):\n",
    "                ax.axvline(years_highlight[p], linestyle='--', color='k',linewidth=1, )\n",
    "        \n",
    "        ################ surf_dil\n",
    "        elif j == 1:\n",
    "            ax = fig.add_subplot(nrow, ncol, i*ncol+j+1)\n",
    "            ax.text(-4, 0.43, 'ii', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            tarray = np.arange(0, 180, 1)/12\n",
    "            \n",
    "            for k in range(4):\n",
    "                ax.plot(tarray, no_nans(surf_dil.isel(season=k).frac_ALK_excess_surf.values), linewidth=2.5, color=colors[k], label=labels[k], alpha=0.6)\n",
    "                ax.set_ylim(0, 0.4)\n",
    "                ax.set_ylabel('Frac. of added Alk in surf.')\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Time since release (years)')\n",
    "                custom_x_ticks = [0, 1, 2, 4, 8, 15]\n",
    "                custom_x_labels  = [str(num) for num in custom_x_ticks]\n",
    "                ax.set_xticks(custom_x_ticks)\n",
    "                ax.set_xticklabels(custom_x_labels);\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "            if i == 0:\n",
    "                ax.legend(loc='upper right')\n",
    "\n",
    "            # add vertical lines\n",
    "            years_highlight = [1, 2, 8]\n",
    "            for p in range(len(years_highlight)):\n",
    "                ax.axvline(years_highlight[p], linestyle='--', color='k',linewidth=1, )\n",
    "\n",
    "\n",
    "        ################ piston velocity\n",
    "        elif j == 2:\n",
    "            ax = fig.add_subplot(nrow, ncol, i*ncol+j+1)\n",
    "            ax.text(-4, 12.5, 'iii', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            tarray = np.arange(0, 180, 1)/12\n",
    "            \n",
    "            for k in range(4):\n",
    "                ax.plot(tarray, no_nans(tau_comp[k].piston_weight_1.values/100*86400), linewidth=1.5, color=colors[k], label=labels[k], alpha=0.1)\n",
    "                ind_not_nan = ~np.isnan(tau_comp[k].piston_weight_1.values)\n",
    "                ax.plot(tarray, tau_comp[k].piston_weight_1.rolling(time=12, min_periods=12, center=True).mean().values[ind_not_nan]/100*86400, linewidth=2.5, color=colors[k], label=labels[k], alpha=0.6)\n",
    "\n",
    "                ax.set_ylim(0, 12)\n",
    "                ax.set_ylabel('$k$ (m/day)')\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Time since release (years)')\n",
    "                custom_x_ticks = [0, 1, 2, 4, 8, 15]\n",
    "                custom_x_labels  = [str(num) for num in custom_x_ticks]\n",
    "                ax.set_xticks(custom_x_ticks)\n",
    "                ax.set_xticklabels(custom_x_labels);\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # add vertical lines\n",
    "            years_highlight = [1, 2, 8]\n",
    "            for p in range(len(years_highlight)):\n",
    "                ax.axvline(years_highlight[p], linestyle='--', color='k',linewidth=1, )\n",
    "                \n",
    "        ################ dDIC_dCO2\n",
    "        elif j == 3:\n",
    "            ax = fig.add_subplot(nrow, ncol, i*ncol+j+1)\n",
    "            ax.text(-4, 29, 'iv', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            tarray = np.arange(0, 180, 1)/12\n",
    "            \n",
    "            for k in range(4):\n",
    "                ax.plot(tarray, no_nans(tau_comp[k].dDICdCO2_approxi_weight_1.values), linewidth=1.5, color=colors[k], label=labels[k], alpha=0.1)\n",
    "                ind_not_nan = ~np.isnan(tau_comp[k].dDICdCO2_approxi_weight_1.values)\n",
    "                ax.plot(tarray, tau_comp[k].dDICdCO2_approxi_weight_1.rolling(time=12, min_periods=12, center=True).mean().values[ind_not_nan], linewidth=2.5, color=colors[k], label=labels[k], alpha=0.6)\n",
    "\n",
    "                ax.set_ylim(7, 28)\n",
    "                ax.set_ylabel('β')\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Time since release (years)')\n",
    "                custom_x_ticks = [0, 1, 2, 4, 8, 15]\n",
    "                custom_x_labels  = [str(num) for num in custom_x_ticks]\n",
    "                ax.set_xticks(custom_x_ticks)\n",
    "                ax.set_xticklabels(custom_x_labels);\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # add vertical lines\n",
    "            years_highlight = [1, 2, 8]\n",
    "            for p in range(len(years_highlight)):\n",
    "                ax.axvline(years_highlight[p], linestyle='--', color='k',linewidth=1, )\n",
    "                \n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "\n",
    "# plt.savefig('./figures/Figure_5.png', dpi=400, bbox_inches='tight')\n",
    "# plt.savefig('./figures/Figure_5.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1658c-4546-49dc-adbd-0ef8d34b19ff",
   "metadata": {},
   "source": [
    "# Fig. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4ed47-beb9-4135-a065-21dd7ce332f6",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cedf25-c38b-4f50-bd5e-3236679c9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_curves_global = xr.open_dataset('./data/curves_Eta_fracExcessALKsurf.nc', decode_times=False)\n",
    "all_curves_global_tau_FG_CO2 = xr.open_dataset('./data/curves_tau_decomposition_noTau.nc', decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ed6ca-2879-4e9e-9a95-3875def461f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface pCO2 deficit at year 2 for January releases\n",
    "ds = xr.open_dataset('./data/plumes_data/pCO2_SURF_excess_0_Atlantic.nc')\n",
    "ds_142 = xr.open_dataset('./data/plumes_data/pCO2_SURF_excess_142_Atlantic.nc')\n",
    "ds_129 = xr.open_dataset('./data/plumes_data/pCO2_SURF_excess_129_Atlantic.nc')\n",
    "ds_126 = xr.open_dataset('./data/plumes_data/pCO2_SURF_excess_126_Atlantic.nc')\n",
    "\n",
    "# vertical distribution of fraction of excess ALK\n",
    "frac_alk_invertical = xr.open_dataset('./data/plumes_data/frac_alk_invertical_0_jan_Atlantic.nc')\n",
    "frac_alk_invertical_apr = xr.open_dataset('./data/plumes_data/frac_alk_invertical_0_apr_Atlantic.nc')\n",
    "frac_alk_invertical_jul = xr.open_dataset('./data/plumes_data/frac_alk_invertical_0_jul_Atlantic.nc')\n",
    "frac_alk_invertical_oct = xr.open_dataset('./data/plumes_data/frac_alk_invertical_0_oct_Atlantic.nc')\n",
    "\n",
    "frac_alk_invertical_142 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_142_jan_Atlantic.nc')\n",
    "frac_alk_invertical_apr_142 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_142_apr_Atlantic.nc')\n",
    "frac_alk_invertical_jul_142 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_142_jul_Atlantic.nc')\n",
    "frac_alk_invertical_oct_142 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_142_oct_Atlantic.nc')\n",
    "\n",
    "frac_alk_invertical_129 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_129_jan_Atlantic.nc')\n",
    "frac_alk_invertical_apr_129 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_129_apr_Atlantic.nc')\n",
    "frac_alk_invertical_jul_129 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_129_jul_Atlantic.nc')\n",
    "frac_alk_invertical_oct_129 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_129_oct_Atlantic.nc')\n",
    "\n",
    "frac_alk_invertical_126 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_126_jan_Atlantic.nc')\n",
    "frac_alk_invertical_apr_126 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_126_apr_Atlantic.nc')\n",
    "frac_alk_invertical_jul_126 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_126_jul_Atlantic.nc')\n",
    "frac_alk_invertical_oct_126 = xr.open_dataset('./data/plumes_data/frac_alk_invertical_126_oct_Atlantic.nc')\n",
    "\n",
    "#### put together\n",
    "dss = [ds, ds_126, ds_142, ds_129]\n",
    "\n",
    "fra_alks = [ [frac_alk_invertical, frac_alk_invertical_apr, frac_alk_invertical_jul, frac_alk_invertical_oct],\\\n",
    "[frac_alk_invertical_126, frac_alk_invertical_apr_126, frac_alk_invertical_jul_126, frac_alk_invertical_oct_126],\\\n",
    "[frac_alk_invertical_142, frac_alk_invertical_apr_142, frac_alk_invertical_jul_142, frac_alk_invertical_oct_142],\\\n",
    "[frac_alk_invertical_129, frac_alk_invertical_apr_129, frac_alk_invertical_jul_129, frac_alk_invertical_oct_129] ]\n",
    "\n",
    "# OAE efficiency curves for only atlantic\n",
    "poly_ind = [0, 126, 142, 129]\n",
    "season = [0,1,2,3]\n",
    "\n",
    "oae_effs = []\n",
    "for p in poly_ind:\n",
    "    l = []\n",
    "    for s in season:\n",
    "        l.append(all_curves_global.isel(region=1, polygon=p, season=s))\n",
    "    oae_effs.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939923c-6cdd-4ec5-b73b-a034a0cbf31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, ii):\n",
    "    # a list of colors\n",
    "    # colorsss = list(mcolors.TABLEAU_COLORS.values())\n",
    "    # ind_color = np.arange(len(colorsss)) # 0- 9\n",
    "\n",
    "    vertices = np.array(final_polygon_vertices_atlantic[ii])\n",
    "    # plot convex hull\n",
    "    if len(vertices) >= 3:\n",
    "        hull = ConvexHull(vertices) # get the indices of the periphery of a patch, for plotting purpose\n",
    "        polygon = list(vertices[iii] for iii in hull.vertices.tolist() )\n",
    "        polygon = np.array(polygon)\n",
    "\n",
    "        ax.plot(np.append(polygon[:,0], polygon[0,0]), np.append(polygon[:,1], polygon[0,1]), 'k-', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # plot polygon masks\n",
    "    index = np.where(final_polygon_mask_atlantic[ii] == 1)\n",
    "    ax.scatter(tlong[index], tlat[index], c='gray', s=1, alpha=0.3, transform=ccrs.PlateCarree())\n",
    "    #ax.text(cluster_centers_atlantic[ii, 0]-2, cluster_centers_atlantic[ii, 1]-1,str(ii), fontsize=9, color='k', transform=ccrs.PlateCarree())\n",
    "\n",
    "# atlantic polygon masks\n",
    "final_polygon_mask_atlantic = np.load('./data/polygon_data/Atlantic_final_polygon_mask.npy')\n",
    "final_polygon_vertices_atlantic = np.load('./data/polygon_data/Atlantic_final_polygon_vertices.npy', allow_pickle=True)\n",
    "cluster_centers_atlantic = np.load('./data/polygon_data/Atlantic_final_cluster_centers.npy', allow_pickle=True)\n",
    "\n",
    "# Adding mixed layer depth weighted by modulus FG_CO2_excess\n",
    "## for only atlantic\n",
    "poly_ind = [0, 126, 142, 129]\n",
    "season = [0,1,2,3]\n",
    "\n",
    "eff_mld = np.zeros((4, 4, 3))  # number of polygons, number of season, number of years\n",
    "\n",
    "for i in range(4): # polygon\n",
    "    for j in range(4): # season\n",
    "        eff_mld[i,j,0] = no_nans(all_curves_global_tau_FG_CO2.isel(region=1, polygon=poly_ind[i], season=j).mld_weight_1.values)[12*1]/100 \n",
    "        eff_mld[i,j,1] = no_nans(all_curves_global_tau_FG_CO2.isel(region=1, polygon=poly_ind[i], season=j).mld_weight_1.values)[12*2]/100\n",
    "        eff_mld[i,j,2] = no_nans(all_curves_global_tau_FG_CO2.isel(region=1, polygon=poly_ind[i], season=j).mld_weight_1.values)[12*8]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9297c1-7f1c-4a83-868b-aad13ac8c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eff_mld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ad2ee-beaa-4657-83e9-f14d50fbee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "gs = gridspec.GridSpec(4, 3, width_ratios=[1, 1, 2])\n",
    "\n",
    "colors = ['blue', 'cyan', 'red', 'orange']\n",
    "labels = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "lon_mins = [-80, -80, -100, -100]\n",
    "lon_maxs = [25, 25, 25, 25]\n",
    "lat_mins = [0, 0, 0, -45]\n",
    "lat_maxs = [80, 80, 80, 47]\n",
    "central_longitudes = [0, 0, 0, 0]\n",
    "region_names  = ['Labrador Sea','Subpol. N. Atlantic','Subtrop. N. Atlantic','Equat. Atlantic']\n",
    "\n",
    "def modify_ax_alk(ax):\n",
    "    ax.set_ylim(5000, 1)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    custom_y_ticks = [10, 100, 500, 1000, 4000]\n",
    "    custom_y_labels  = [str(num) for num in custom_y_ticks]\n",
    "    ax.set_yticks(custom_y_ticks)\n",
    "    ax.set_yticklabels(custom_y_labels);\n",
    "    \n",
    "    ax.set_xlim(-0.01, 0.6)\n",
    "    custom_x_ticks = np.arange(0, 0.7, 0.1)\n",
    "    custom_x_labels  = [0, 0.1, 0, 0.1, 0, 0.1, 0.2]\n",
    "    custom_x_labels = [str(num) for num in custom_x_labels]\n",
    "    ax.set_xticks(custom_x_ticks)\n",
    "    ax.set_xticklabels(custom_x_labels);\n",
    "\n",
    "\n",
    "for i in range(4): # polygon\n",
    "    oae_ = oae_effs[i] # OAE_result for a polygon\n",
    "    frac_alk_ = fra_alks[i] # frac_alk for a polygon\n",
    "    \n",
    "    for j in range(3):\n",
    "        if j == 0:\n",
    "            #ax = fig.add_subplot(4, 3, i*3+j+1, projection=ccrs.PlateCarree(central_longitude=central_longitudes[i]))\n",
    "            ax = plt.subplot(gs[i, j], projection=ccrs.PlateCarree(central_longitude=central_longitudes[i]))\n",
    "            ax.text(-0.4, 0.5, f'{region_names[i]}', ha='center', va='center', rotation=90, transform=ax.transAxes, fontsize=17)  \n",
    "\n",
    "            ### add map\n",
    "            ds_ = util.pop_add_cyclic(dss[i])\n",
    "\n",
    "            lon_min = lon_mins[i]\n",
    "            lon_max = lon_maxs[i]\n",
    "            lat_min = lat_mins[i]\n",
    "            lat_max = lat_maxs[i]\n",
    "\n",
    "            custom_colorbar_ticks = [1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "            negated_numbers = [-num for num in custom_colorbar_ticks]\n",
    "            custom_colorbar_labels  = [str(num) for num in negated_numbers]\n",
    "\n",
    "            sca = ax.contourf(ds_.TLONG, ds_.TLAT, -ds_.pCO2_SURF_excess,\n",
    "                              transform=ccrs.PlateCarree(),\n",
    "                              cmap=plt.cm.cool,\n",
    "\n",
    "                              levels = custom_colorbar_ticks,\n",
    "                              # #levels=[-1e1, -1e0, -1e-1, -1e-2, -1e-3, -1e-4],\n",
    "                              extend='max',\n",
    "                              norm=LogNorm(),              \n",
    "                             );\n",
    "            def modify(ax):\n",
    "                ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "                ax.set_xticks(np.arange(lon_min+20, lon_max, 60), crs=ccrs.PlateCarree())\n",
    "                ax.set_yticks(np.arange( lat_min+30, lat_max, 30), crs=ccrs.PlateCarree())\n",
    "                lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "                lat_formatter = LatitudeFormatter()\n",
    "                ax.xaxis.set_major_formatter(lon_formatter)\n",
    "                ax.yaxis.set_major_formatter(lat_formatter) \n",
    "\n",
    "                ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "###### colorbar\n",
    "                if i == 0:\n",
    "                    cax = fig.add_axes([-0.27, 0.085, 1, 0.05])  # left, bottom, width, height\n",
    "                    cb = fig.colorbar(sca, ax=cax, shrink=1, orientation='horizontal')\n",
    "                    cb.ax.set_title('Surface $pCO_2$ deficit (µatm)', y=-6, fontsize=13)\n",
    "                    cb.set_ticks(custom_colorbar_ticks)\n",
    "                    cb.set_ticklabels(custom_colorbar_labels)\n",
    "                    cb.ax.tick_params(axis='x', labelsize=11)\n",
    "                \n",
    "            modify(ax)\n",
    "            \n",
    "            ## add polygons\n",
    "            if i == 0:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 0)\n",
    "                ax.text(-108, 82, 'a, i', fontsize=16, fontweight='bold')\n",
    "            elif i == 1:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 126)\n",
    "                ax.text(-108, 82, 'b, i', fontsize=16, fontweight='bold')\n",
    "            elif i == 2:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 142)\n",
    "                ax.text(-128, 84, 'c, i', fontsize=16, fontweight='bold')\n",
    "            elif i == 3:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 129)\n",
    "                ax.text(-128, 52, 'd, i', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        ################ oae eff\n",
    "        elif j == 1:\n",
    "            #ax = fig.add_subplot(4, 3, i*3+j+1)\n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            ax.text(-4, 0.9, 'ii', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            tarray = np.arange(0, 180, 1)/12\n",
    "            \n",
    "            for k in range(4):\n",
    "                ax.plot(tarray, no_nans(oae_[k].OAE_efficiency.values), linewidth=2, color=colors[k], label=labels[k])\n",
    "                ax.set_ylim(0, 0.9)\n",
    "                ax.set_ylabel('OAE efficiency')\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Time since release (years)')\n",
    "                custom_x_ticks = [0, 1, 2, 4, 8, 15]\n",
    "                custom_x_labels  = [str(num) for num in custom_x_ticks]\n",
    "                ax.set_xticks(custom_x_ticks)\n",
    "                ax.set_xticklabels(custom_x_labels);\n",
    "            else:\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # add vertical lines\n",
    "            years_highlight = [1, 2, 8]\n",
    "            for p in range(len(years_highlight)):\n",
    "                ax.axvline(years_highlight[p], linestyle='--', color='k',linewidth=1, )\n",
    "                \n",
    "            if i == 1:\n",
    "                ax.legend(loc='lower right')\n",
    "\n",
    "        ################ vertical profiles of excess alk\n",
    "        elif j == 2:\n",
    "            #ax = fig.add_subplot(4, 3, i*3+j+1)\n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            ax.text(-0.05, 1.2, 'iii', fontsize=16, fontweight='bold')\n",
    "            depth_array = frac_alk_invertical.z_t.values/100  # m\n",
    "            \n",
    "            mld_ = eff_mld[i] # mld for this polygon\n",
    "            for k in range(4): # for a season\n",
    "                ax.plot(frac_alk_[k].frac_alk.isel(time=12*1), depth_array, linewidth=2, color=colors[k], label=labels[k], linestyle='-')\n",
    "                ax.plot(frac_alk_[k].frac_alk.isel(time=12*2) + 0.2, depth_array, linewidth=2, color=colors[k], linestyle='-')\n",
    "                ax.plot(frac_alk_[k].frac_alk.isel(time=12*8) + 0.4, depth_array, linewidth=2, color=colors[k], linestyle='-')\n",
    "                \n",
    "                # add mld for year 1, 2, 8\n",
    "                ax.plot([0, 0.2-0.04], [mld_[k,0], mld_[k,0]], color=colors[k], linestyle=':', linewidth=2)\n",
    "                ax.plot([0.2, 0.4-0.04], [mld_[k,1], mld_[k,1]], color=colors[k], linestyle=':', linewidth=2)\n",
    "                ax.plot([0.4, 0.6-0.04], [mld_[k,2], mld_[k,2]], color=colors[k], linestyle=':', linewidth=2)\n",
    "                \n",
    "                \n",
    "            modify_ax_alk(ax)\n",
    "            ax.set_ylabel('Depth (m)')\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Fraction of total excess Alk')\n",
    "            else:\n",
    "                ax.set_xticklabels([]);\n",
    "            if i == 0:\n",
    "                #ax.legend(loc='upper right')\n",
    "                ax.text(0.02, 4, f'After 1 year')\n",
    "                ax.text(0.22, 4, f'2 years')\n",
    "                ax.text(0.42, 4, f'8 years')\n",
    "                \n",
    "                \n",
    "                \n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.2)\n",
    "\n",
    "# plt.savefig('./figures/Figure_2.png', dpi=400, bbox_inches='tight')\n",
    "# plt.savefig('./figures/Figure_2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768def1-ae12-4824-9d73-e7f1742e9453",
   "metadata": {},
   "source": [
    "## Numbers in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96f0bc-6ea8-47d2-9d32-9bfa736b7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,15,180), no_nans(oae_effs[1][2].OAE_efficiency.values))\n",
    "plt.plot(np.linspace(0,15,180), no_nans(oae_effs[3][2].OAE_efficiency.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79858bb-c936-429a-94dc-a67d2e966c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon 126\n",
    "arr = no_nans(oae_effs[1][2].OAE_efficiency.values)\n",
    "\n",
    "# Keeping only two decimals\n",
    "arr_rounded = np.round(arr, decimals=2)\n",
    "\n",
    "# Finding the index of the maximum element\n",
    "max_index = np.argmax(arr_rounded)\n",
    "index = np.argmax(arr_rounded >= 0.8)\n",
    "\n",
    "\n",
    "max_index/12, index/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a20d2b-dcb8-45b3-a602-4e315970e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ebdfe-7432-4d8d-a56b-cf8d76e52f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon equator\n",
    "arr = no_nans(oae_effs[3][2].OAE_efficiency.values)\n",
    "\n",
    "# Keeping only two decimals\n",
    "arr_rounded = np.round(arr, decimals=2)\n",
    "\n",
    "# Finding the index of the maximum element\n",
    "max_index = np.argmax(arr_rounded)\n",
    "\n",
    "max_index/12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c2370-17ef-4208-b66d-64a1dce22aa7",
   "metadata": {},
   "source": [
    "# Adding histograms of CO2 uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8adac-d3c4-40b7-83dd-54045069d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poly = xr.open_dataset('./data/curves_CO2spread.nc')\n",
    "ds_4poly = all_poly.sel(region='North_Atlantic_basin', polygon=[0,126,142,129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8db1fe-a29d-4a95-9fcb-591631bba867",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_4poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29a10f-e406-40f0-ac10-672186aa30e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Map view of cumulative CO2 uptake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9953a8-41b2-45de-b1d4-f4918a617254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumul_CO2uptake_map(polygon, reg='North_Atlantic_basin'):\n",
    "    \n",
    "    fpath = './data/FG_CO2_excess/'\n",
    "\n",
    "    ind = polygon*4\n",
    "    FG_CO2_excess = xr.open_dataset(fpath + f'{reg}-{ind:04d}.nc')\n",
    "    \n",
    "    FG_CO2_excess_area_time = (FG_CO2_excess.FG_CO2_excess * FG_CO2_excess.TAREA * FG_CO2_excess.time_delta) / 1e6 * 86400 # mmol\n",
    "    total_FG_CO2 = FG_CO2_excess_area_time.sum(dim=['time', 'nlat', 'nlon']).values # total CO2 uptake in 15 years, mmol\n",
    "\n",
    "    frac_FG_CO2 = FG_CO2_excess_area_time / total_FG_CO2*100\n",
    "    frac_FG_CO2_cumul = frac_FG_CO2.sum(['time'])\n",
    "    \n",
    "    frac_FG_CO2_cumul = frac_FG_CO2_cumul.to_dataset(name='frac_FG_CO2_cumul')\n",
    "    \n",
    "    return frac_FG_CO2_cumul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9f1a8-b7f4-445f-bfc6-5ca5e57f15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "frac_FG_CO2_map_0 = get_cumul_CO2uptake_map(0)\n",
    "frac_FG_CO2_map_142 = get_cumul_CO2uptake_map(142)\n",
    "frac_FG_CO2_map_129 = get_cumul_CO2uptake_map(129)\n",
    "frac_FG_CO2_map_126 = get_cumul_CO2uptake_map(126)\n",
    "\n",
    "ds_frac_FG_CO2_map = [frac_FG_CO2_map_0, frac_FG_CO2_map_126, frac_FG_CO2_map_142, frac_FG_CO2_map_129]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6150cf-5d8c-455e-92c5-6ce47f1ee181",
   "metadata": {},
   "source": [
    "Given ranges, calculate sums inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1b509-845c-4f1f-adc4-3ae914ac6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_inside(frac_FG_CO2_map_63, ranges):\n",
    "    '''\n",
    "    Given a list of max_values, return the sums inside\n",
    "    '''\n",
    "    data_array = frac_FG_CO2_map_63.frac_FG_CO2_cumul\n",
    "\n",
    "    l_sum_inside = []\n",
    "    for max_value in ranges:\n",
    "        selected_data = data_array.where( (data_array >= max_value), drop=True)\n",
    "        sum_inside = selected_data.sum(dim=['nlat', 'nlon']).values.item()\n",
    "        l_sum_inside.append(sum_inside)\n",
    "    return np.array(l_sum_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2c801-84ad-4c03-bf2c-e1da588ab4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [1e-3, 0.008, 0.02, 0.1]\n",
    "print(get_sum_inside(frac_FG_CO2_map_0, ranges))\n",
    "print(get_sum_inside(frac_FG_CO2_map_126, ranges))\n",
    "print(get_sum_inside(frac_FG_CO2_map_142, ranges))\n",
    "print(get_sum_inside(frac_FG_CO2_map_129, ranges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951616d8-bf98-4e77-b78a-b2198ad3be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = get_sum_inside(frac_FG_CO2_map_0, ranges)\n",
    "int_array = list(map(int, arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e83c21-0222-4da9-b825-84c1ba3a0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9cfca-80a9-4b58-a66d-2e209e49997e",
   "metadata": {},
   "source": [
    "Given the sums, what should be the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b53f0-c15a-479d-b885-a579cbc963a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_values(frac_FG_CO2_map_63, target_sums, thresholds):\n",
    "    '''\n",
    "    Given an array of target_sum, return the max values that will sum to the targets.\n",
    "    '''\n",
    "\n",
    "    l_max_value = []\n",
    "\n",
    "    data_array = frac_FG_CO2_map_63.frac_FG_CO2_cumul\n",
    "    \n",
    "    for target, thres in zip(target_sums, thresholds):\n",
    "\n",
    "        max_value = np.round(data_array.max().item(), 2) # start value\n",
    "        \n",
    "        #print(\"Target:\", target)\n",
    "        \n",
    "        # Iterate to find the largest max_value that makes the sum equal to the target value\n",
    "        while True:\n",
    "            \n",
    "            selected_data = data_array.where(data_array >= max_value, drop=True)\n",
    "            sum_inside = selected_data.sum(dim=['nlat', 'nlon']).values\n",
    "            \n",
    "            #print(max_value, sum_inside,target, np.abs(sum_inside - target))\n",
    "\n",
    "            if sum_inside - target >= thres:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Decrease max_value for the next iteration\n",
    "                max_value -= 0.005\n",
    "        \n",
    "        l_max_value.append(max_value)\n",
    "        #print(\"Largest max_values:\", l_max_value)\n",
    "    #l_max_value.append(0.001)\n",
    "        \n",
    "    return l_max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d98e5-cc7c-4da3-aa11-35267ef1e110",
   "metadata": {},
   "source": [
    "Figure out the labels and ranges one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd244df8-eb20-4e29-baff-a44c0e678808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(frac_FG_CO2_map_0, the_num):\n",
    "    \n",
    "    data_array = frac_FG_CO2_map_0.frac_FG_CO2_cumul\n",
    "    selected_data = data_array.where( (data_array >= the_num), drop=True)\n",
    "    sum_inside = selected_data.sum(dim=['nlat', 'nlon']).values.item()\n",
    "    return sum_inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fb4f8-a0ee-4060-9ef5-270b8a2a0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max_value = []\n",
    "L_target_sums = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212a34e-1c95-41f5-bccc-2679c13cfe26",
   "metadata": {},
   "source": [
    "Polygon 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0874b-a982-4286-bebf-522cdd211c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sums = [30, 50, 70, ]\n",
    "thresholds = [0.3, 0.3, 0.3, ]\n",
    "l_max_value = get_max_values(frac_FG_CO2_map_0, target_sums, thresholds)\n",
    "\n",
    "the_num = 0.0135\n",
    "sum_inside = get_sum(frac_FG_CO2_map_0, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "the_num = 0.0065\n",
    "sum_inside = get_sum(frac_FG_CO2_map_0, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "l_max_value.reverse()\n",
    "target_sums.reverse()\n",
    "\n",
    "l_max_value, target_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024dc51d-21a7-4cd1-9fa7-5a61a72703d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max_value.append(l_max_value)\n",
    "L_target_sums.append(target_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb55b20-1653-479b-bc07-57d9443e8c96",
   "metadata": {},
   "source": [
    "Polygon 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b5a932-2f47-4c25-8ab2-3174c0e78fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlantic 126\n",
    "target_sums = [30, 50, 70]\n",
    "thresholds = [0.3, 0.3, 0.3]\n",
    "l_max_value = get_max_values(frac_FG_CO2_map_126, target_sums, thresholds)\n",
    "\n",
    "the_num = 0.0068\n",
    "sum_inside = get_sum(frac_FG_CO2_map_126, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "the_num = 0.00365\n",
    "sum_inside = get_sum(frac_FG_CO2_map_126, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "l_max_value.reverse()\n",
    "target_sums.reverse()\n",
    "\n",
    "l_max_value, target_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a606e4c-6841-4cd3-8cde-0f4d946ba859",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max_value.append(l_max_value)\n",
    "L_target_sums.append(target_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746ab32-800b-473f-9193-b45aa380652b",
   "metadata": {},
   "source": [
    "Polygon 142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264cb97-157c-4f79-a38b-523d41f628c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sums = [30, 50, 70]\n",
    "thresholds = [0.3, 0.3, 0.3]\n",
    "l_max_value = get_max_values(frac_FG_CO2_map_142, target_sums, thresholds)\n",
    "\n",
    "the_num = 0.0041\n",
    "sum_inside = get_sum(frac_FG_CO2_map_142, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "the_num = 0.0022\n",
    "sum_inside = get_sum(frac_FG_CO2_map_142, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "l_max_value.reverse()\n",
    "target_sums.reverse()\n",
    "\n",
    "l_max_value, target_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb4b09-b71d-4bc8-9fb6-740460890fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max_value.append(l_max_value)\n",
    "L_target_sums.append(target_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8ca61-8b54-4440-80e8-4f8a8c11780e",
   "metadata": {},
   "source": [
    "Polygon 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856ea34-6b2a-42ee-b9d4-f131ad1bf96a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_sums = [30, 50, 70]\n",
    "thresholds = [0.3, 0.3, 0.3]\n",
    "l_max_value = get_max_values(frac_FG_CO2_map_129, target_sums, thresholds)\n",
    "\n",
    "the_num = 0.0027\n",
    "sum_inside = get_sum(frac_FG_CO2_map_129, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "the_num = 0.0015\n",
    "sum_inside = get_sum(frac_FG_CO2_map_129, the_num)\n",
    "target_sums.append(sum_inside)\n",
    "l_max_value.append(the_num)\n",
    "\n",
    "l_max_value.reverse()\n",
    "target_sums.reverse()\n",
    "\n",
    "l_max_value, target_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfae9a-279c-414c-92eb-b8c76b927419",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_max_value.append(l_max_value)\n",
    "L_target_sums.append(target_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff3294-fcb7-402d-b130-2c9153e311a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, ii):\n",
    "    # a list of colors\n",
    "    # colorsss = list(mcolors.TABLEAU_COLORS.values())\n",
    "    # ind_color = np.arange(len(colorsss)) # 0- 9\n",
    "\n",
    "    vertices = np.array(final_polygon_vertices_atlantic[ii])\n",
    "    # plot convex hull\n",
    "    if len(vertices) >= 3:\n",
    "        hull = ConvexHull(vertices) # get the indices of the periphery of a patch, for plotting purpose\n",
    "        polygon = list(vertices[iii] for iii in hull.vertices.tolist() )\n",
    "        polygon = np.array(polygon)\n",
    "\n",
    "        ax.plot(np.append(polygon[:,0], polygon[0,0]), np.append(polygon[:,1], polygon[0,1]), 'k-', linewidth=0.5, alpha=0.3, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # plot polygon masks\n",
    "    index = np.where(final_polygon_mask_atlantic[ii] == 1)\n",
    "    ax.scatter(tlong[index], tlat[index], c='gray', s=1, alpha=0.3, transform=ccrs.PlateCarree())\n",
    "    #ax.text(cluster_centers_atlantic[ii, 0]-2, cluster_centers_atlantic[ii, 1]-1,str(ii), fontsize=9, color='k', transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d1217-a515-4d91-bc88-f52d014f9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds_4poly.isel(polygon=0).mean(dim='season').FG_CO2_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b0f0b-0215-45cf-9b3e-3c8813129f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_dist(FG_CO2_rings_per, long=False):\n",
    "\n",
    "    all_rs = [3,6,12,24,72,180]\n",
    "    r=0\n",
    "    stacks = []\n",
    "    labels = []\n",
    "\n",
    "    for rs in all_rs:\n",
    "        # sum individual histograms across the time axis into groups.\n",
    "        sum_over_time = np.sum(FG_CO2_rings_per[r:rs],axis=0)*100\n",
    "        cum_sum = np.cumsum(sum_over_time)\n",
    "        stacks.append(cum_sum)\n",
    "        percentage = np.sum(cum_sum[-1])\n",
    "\n",
    "        if long==True:\n",
    "            labels.append(\"%.1f %% in months %d-%d\"%(percentage,r,rs))\n",
    "        else:\n",
    "            labels.append(\"%.1f %%\"%(percentage))\n",
    "        # move to the next block\n",
    "        #r=rs\n",
    "        \n",
    "    return stacks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73edbd55-302d-40cc-9e54-f3b1f1616cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacks, labels = get_cumulative_dist(temp, long=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd59b6b-33c0-4acb-8238-c9d44b9add62",
   "metadata": {},
   "source": [
    "# Fig. 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e6b5d-8e47-46ad-952f-6054c7f6ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b801d00-55e9-4c69-9316-b6fe29a89396",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds = xr.open_dataset('./data/uptake_percent_maps.nc')\n",
    "\n",
    "mean_over_season = whole_ds.mean(dim='season')\n",
    "mean_over_season = util.pop_add_cyclic(mean_over_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda5b0e-dfe4-4881-917f-1c992713c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786bf479-7f39-4ba4-b861-cd898a5c7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize=(15,11))\n",
    "gs = gridspec.GridSpec(4, 3, width_ratios=[2, 1, 1])\n",
    "\n",
    "# Separate the first column into 3 rows\n",
    "gs_sub1 = gs[:, 0].subgridspec(3, 1, height_ratios=[1, 1, 1], hspace=0.1)\n",
    "\n",
    "# Now you can access the subgridspec for the first column like this:\n",
    "ax1 = plt.subplot(gs_sub1[0, 0])\n",
    "ax2 = plt.subplot(gs_sub1[1, 0])\n",
    "ax3 = plt.subplot(gs_sub1[2, 0])\n",
    "\n",
    "\n",
    "################## global maps\n",
    "time_window = 180\n",
    "dist2center = 1000\n",
    "\n",
    "FONTSIZE = 14\n",
    "def modify(ax):\n",
    "    ax.set_extent([0, 360, -85, 80], crs=ccrs.PlateCarree())\n",
    "    #ax.stock_img()\n",
    "    ax.imshow(imread('./lightearth.jpg'),origin='upper', transform=ccrs.PlateCarree(), extent=[-180, 180, -90, 90])\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter) \n",
    "\n",
    "central_longitude=208\n",
    "\n",
    "dist2center = [500, 1000, 2000]\n",
    "labels = ['a  500 km', 'b  1000 km', 'c  2000 km']\n",
    "\n",
    "for i in range(3):\n",
    "    ax = plt.subplot(gs_sub1[i, 0],  projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "    #ax = fig.add_subplot(2, 2, i+1, projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "    ax.pcolormesh(mean_over_season.TLONG, mean_over_season.TLAT, mean_over_season.sel(time_window=time_window, dist2center=dist2center[i]).uptake_percent, transform=ccrs.PlateCarree(), cmap='viridis', vmin=0, vmax=100)\n",
    "    \n",
    "    ax.text(40, 60, labels[i][3:], fontsize=FONTSIZE, transform=ccrs.PlateCarree(), fontweight='bold')\n",
    "    ax.text(30, 85, labels[i][:1], fontsize=FONTSIZE, transform=ccrs.PlateCarree(), fontweight='bold')\n",
    "    ax.set_yticks([-60,-30,0,30,60], crs=ccrs.PlateCarree())\n",
    "    ax.set_yticklabels(ax.get_yticks(), fontsize=FONTSIZE)\n",
    "    ax.set_xticks(np.arange(0, 360, 60), crs=ccrs.PlateCarree())\n",
    "    ax.set_xticklabels(ax.get_xticks(), fontsize=FONTSIZE)\n",
    "        \n",
    "    modify(ax)\n",
    "    \n",
    "def add_colorbar(x0, y0, vmin, vmax, label, num_levels_ticks, cmap_label='viridis'):\n",
    "    '''\n",
    "    x0, y0: start location for the colorbar\n",
    "    vmin, vmax: range of the colorbar\n",
    "    label: label of the colorbar'\n",
    "    '''\n",
    "    cax = fig.add_axes([x0, y0, 0.2, 0.02])  # [x0, y0, width, height]\n",
    "    cmap = plt.colormaps[cmap_label]\n",
    "    normalize = plt.Normalize(vmin=vmin, vmax=vmax)  # Normalize the color values\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=normalize)\n",
    "    cbar = fig.colorbar(sm, cax=cax, shrink=0.5, label=label, orientation='horizontal', ticks=np.linspace(vmin, vmax, num_levels_ticks))\n",
    "    cbar.ax.tick_params(labelsize=FONTSIZE)\n",
    "    cbar.ax.xaxis.label.set_size(FONTSIZE)\n",
    "\n",
    "add_colorbar(0.18, 0.07, 0, 100, '% of $CO_2$ uptake', 6)\n",
    "\n",
    "\n",
    "##################################### last 2 columns\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "labels = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "lon_mins = [-80, -80, -100, -100]\n",
    "lon_maxs = [25, 25, 25, 25]\n",
    "lat_mins = [0, 0, 0, -45]\n",
    "lat_maxs = [80, 80, 80, 47]\n",
    "central_longitudes = [0, 0, 0, 0]\n",
    "bin_edges_0 = np.arange(0, 4100*1e3, 50*1e3)\n",
    "\n",
    "def modify_ax_alk(ax):\n",
    "    ax.set_ylim(5000, 1)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    custom_y_ticks = [10, 100, 500, 1000, 4000]\n",
    "    custom_y_labels  = [str(num) for num in custom_y_ticks]\n",
    "    ax.set_yticks(custom_y_ticks)\n",
    "    ax.set_yticklabels(custom_y_labels);\n",
    "    \n",
    "    ax.set_xlim(-0.01, 0.6)\n",
    "    custom_x_ticks = np.arange(0, 0.7, 0.1)\n",
    "    custom_x_labels  = [0, 0.1, 0, 0.1, 0, 0.1, 0.2]\n",
    "    custom_x_labels = [str(num) for num in custom_x_labels]\n",
    "    ax.set_xticks(custom_x_ticks)\n",
    "    ax.set_xticklabels(custom_x_labels);\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    oae_ = oae_effs[i] # OAE_result for a region\n",
    "    frac_alk_ = fra_alks[i] # frac_alk for a region\n",
    "    surf_dil = all_curves_global.sel(region=reg, polygon=polys[i])  # surface dilution curves for a polygon, with 4 seasons\n",
    "    tau_comp = all_curves_global_tau_FG_CO2.sel(region=reg, polygon=polys[i]) # tau gax componets for a region\n",
    "\n",
    "    \n",
    "    for j in range(3):\n",
    "       \n",
    "        if j == 2:\n",
    "            \n",
    "            ax = plt.subplot(gs[i, j], projection=ccrs.PlateCarree(central_longitude=central_longitudes[i]))\n",
    "            \n",
    "            ### add map\n",
    "            ds_ = util.pop_add_cyclic(ds_frac_FG_CO2_map[i])\n",
    "\n",
    "            lon_min = lon_mins[i]\n",
    "            lon_max = lon_maxs[i]\n",
    "            lat_min = lat_mins[i]\n",
    "            lat_max = lat_maxs[i]\n",
    "            \n",
    "            custom_colorbar_ticks = L_max_value[i]\n",
    "\n",
    "            sca = ax.contour(ds_.TLONG, ds_.TLAT, ds_.frac_FG_CO2_cumul,\n",
    "                              transform=ccrs.PlateCarree(),\n",
    "                              cmap=plt.cm.RdYlGn,\n",
    "                              levels = custom_colorbar_ticks,\n",
    "                              extend='both',\n",
    "                              linewidth=2.3\n",
    "                              #norm=LogNorm(),           \n",
    "                             );\n",
    "\n",
    "            # Specify different colors for each level\n",
    "            # contour_colors = ['blue', 'cyan', 'orange', 'red', 'purple']\n",
    "            \n",
    "            # Sample colors from the colormap\n",
    "            cmap = plt.get_cmap('viridis')\n",
    "            contour_colors = [cmap(i) for i in np.linspace(0, 1, 5)][::-1]\n",
    "            \n",
    "            #contour_colors.reverse()\n",
    "            for o, collection in enumerate(sca.collections):\n",
    "                collection.set_edgecolor(contour_colors[o])\n",
    "            \n",
    "            #### add numbers in contour lines\n",
    "            # arr = get_sum_inside(ds_, ranges)\n",
    "            # int_array = list(map(int, arr))\n",
    "\n",
    "            \n",
    "            fmt = {}\n",
    "            strs = [str(ele)+'%' for ele in L_target_sums[i]]\n",
    "            print(strs)\n",
    "            for l, s in zip(sca.levels, strs):\n",
    "                fmt[l] = s\n",
    "            \n",
    "            # Label every other level using strings\n",
    "            ax.clabel(sca, sca.levels, inline=True, fmt=fmt, fontsize=20, inline_spacing=3, colors='k')\n",
    "\n",
    "                    \n",
    "            def modify(ax):\n",
    "                ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "                ax.set_xticks(np.arange(lon_min+20, lon_max, 60), crs=ccrs.PlateCarree())\n",
    "                ax.set_yticks(np.arange( lat_min+30, lat_max, 30), crs=ccrs.PlateCarree())\n",
    "                lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "                lat_formatter = LatitudeFormatter()\n",
    "                ax.xaxis.set_major_formatter(lon_formatter)\n",
    "                ax.yaxis.set_major_formatter(lat_formatter) \n",
    "                #ax.imshow(imread('./lightearth.jpg'),origin='upper', transform=ccrs.PlateCarree(), extent=[-180, 180, -90, 90])\n",
    "\n",
    "                ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "            modify(ax)\n",
    "            ## add polygons\n",
    "            if i == 0:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 0)\n",
    "                ax.text(-100, 78, 'ii', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 1:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 126)\n",
    "                ax.text(-100, 78, 'ii', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 2:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 142)\n",
    "                ax.text(-120, 82, 'ii', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 3:\n",
    "                plot_polygons(ax, final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, 129)\n",
    "                ax.text(-120, 52, 'ii', fontsize=FONTSIZE, fontweight='bold')\n",
    "                percents = [30, 50, 70, 90, 95]\n",
    "                for kk in range(5):\n",
    "                    ax.text(-120 + kk*35, -80, f'{percents[kk]}%', fontsize=16, fontweight='bold', color=contour_colors[4-kk])\n",
    "\n",
    "                \n",
    "        ################## seasonla mean, CO2 uptake histogram\n",
    "        elif j == 1:\n",
    "       \n",
    "            ax = plt.subplot(gs[i, j])\n",
    "            \n",
    "            temp = ds_4poly.isel(polygon=i).mean(dim='season').FG_CO2_percent.values\n",
    "            if i == 0:\n",
    "                stacks, _ = get_cumulative_dist(temp, long=True)\n",
    "            else:\n",
    "                stacks, _ = get_cumulative_dist(temp)\n",
    "\n",
    "            legends = ['3 months', '6 months', '1 year', '2 years','3 years', '15 years']\n",
    "            # Sample colors from the colormap\n",
    "            cmap = plt.get_cmap('viridis')\n",
    "            contour_colors = [cmap(i) for i in np.linspace(0, 1, 6)]\n",
    "\n",
    "            for jj in range(len(stacks)):\n",
    "                ax.plot(bin_edges_0/1000, stacks[jj], label=legends[jj], linewidth=2.3, color=contour_colors[jj])\n",
    "\n",
    "            ### add dashed line\n",
    "            ind_1000 = np.where(bin_edges_0/1000 == 1000)\n",
    "            ax.plot([1000, 1000], [0, stacks[-1][ind_1000]], 'k--')\n",
    "            ax.plot([0, 1000], [stacks[-1][ind_1000], stacks[-1][ind_1000]], 'k--')\n",
    "\n",
    "            ind_2000 = np.where(bin_edges_0/1000 == 2000)\n",
    "            ax.plot([2000, 2000], [0, stacks[-1][ind_2000]], 'k--')\n",
    "            ax.plot([0, 2000], [stacks[-1][ind_2000], stacks[-1][ind_2000]], 'k--')\n",
    "\n",
    "            print('Percentage in 1000, 2000 km', stacks[-1][ind_1000], stacks[-1][ind_2000])\n",
    "\n",
    "            if i == 1:\n",
    "                ax.legend(fontsize=11, loc='lower right')\n",
    "            \n",
    "            ax.set_xlim(-60,4000)\n",
    "            \n",
    "            ax.set_xticklabels('')\n",
    "            ax.set_ylim(-0.2, 100)\n",
    "            if i == 3:\n",
    "                ax.set_xlabel('Distance from addition center (km)')\n",
    "                ax.set_xticks(np.arange(0,5000,1000))\n",
    "                ax.set_xticklabels(np.arange(0,5000,1000))\n",
    "            \n",
    "            ax.set_yticks(np.arange(0,125,25))\n",
    "            ax.set_yticklabels(np.arange(0,125,25))\n",
    "        \n",
    "            if i == 0:\n",
    "                ax.text(-1500, 105, 'd, i', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 1:\n",
    "                ax.text(-1500, 105, 'e, i', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 2:\n",
    "                ax.text(-1500, 105, 'f, i', fontsize=FONTSIZE, fontweight='bold')\n",
    "            elif i == 3:\n",
    "                ax.text(-1500, 105, 'g, i', fontsize=FONTSIZE, fontweight='bold')\n",
    "            \n",
    "            ax.set_ylabel('% of $CO_2$ uptake')\n",
    "\n",
    "            \n",
    "                \n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.2)\n",
    "\n",
    "# plt.savefig('./figures/Figure_6.png', dpi=400, bbox_inches='tight')\n",
    "# plt.savefig('./figures/Figure_6.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b1d3f-f9fb-44c6-b12b-429f86a0d9d5",
   "metadata": {},
   "source": [
    "## numbers in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe65b56-1d2a-4d3e-8433-55bc1712f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds_4poly.isel(polygon=1).mean(dim='season').FG_CO2_percent.values\n",
    "stacks, _ = get_cumulative_dist(temp)\n",
    "# ['3 months', '6 months', '1 year', '2 years','3 years', '15 years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd155b3a-b510-481a-a5c4-5934e001f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 2\n",
    "stacks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a27f75-022f-4c64-8d56-403ef0b6f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of 1000km\n",
    "np.argmax(bin_edges_0/1000 == 1000), np.argmax(bin_edges_0/1000 == 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1007c5-f641-4efb-97a5-e4b5adb56554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year 15\n",
    "stacks[-1][20], stacks[-1][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd307e4-f0e7-44a9-994a-48d3f050d2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
