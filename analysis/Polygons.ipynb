{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3309a0b9-fd86-4bcd-ad59-8d85f6cefac0",
   "metadata": {},
   "source": [
    "This notebook contains code of generating polygons that cover the global ocean\n",
    "for the manuscript. <br>\n",
    "It generates slightly different polygons each time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24932d09-4813-4b64-a533-43df0a772f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import gsw\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pop_tools\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import cmocean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull, Delaunay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d28e60-0689-4f61-b685-6a0aa1d0a48f",
   "metadata": {},
   "source": [
    "# Generate polygons that cover the global ocean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524f812-c6cd-464e-9ed9-583140a27f0a",
   "metadata": {},
   "source": [
    "## Get the grid ready: identify coastline and EEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14a62a-f9b1-4d46-8852-7db0dc2a1c18",
   "metadata": {},
   "source": [
    "Identify coastline in grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489ce37-8076-447b-94ff-54b04cec30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coast_mask(grid):\n",
    "    \n",
    "    '''Add coastline mask to POP grid\n",
    "    \n",
    "    Find coastline coordinates in POP grid: look for sharp gradient of KMT, first make 0 KMT to be 0.0001\n",
    "    \n",
    "    Key: calculate gradients between lon = 319 and nlon = 0 \n",
    "    '''\n",
    "    \n",
    "    ocean_mask = (grid.KMT > 0).values\n",
    "\n",
    "    # Replace zeros with 1e-4 using np.where()\n",
    "    kmt = grid.KMT.values\n",
    "    kmt_ = np.where(kmt == 0, 1e5, kmt)\n",
    "\n",
    "    # Calculate the gradients in both dimensions\n",
    "    gradient_x, gradient_y = np.gradient(kmt_)\n",
    "\n",
    "    # Compute the magnitude of the gradients\n",
    "    gradient_magnitude = np.sqrt(gradient_x ** 2 + gradient_y ** 2)\n",
    "\n",
    "    # for nlon = 319, and nlon = 0, at the edge of POP grid\n",
    "    grad_x, grad_y = np.gradient(kmt_[:, [0, 319]])\n",
    "    gradient_edge = np.sqrt(grad_x ** 2 + grad_y ** 2)\n",
    "\n",
    "    # Find the indices where the gradient magnitude exceeds the threshold\n",
    "    coast_indices = np.where(gradient_magnitude > 40000)\n",
    "    coast_indices_edge = np.where(gradient_edge > 40000)\n",
    "\n",
    "    # conbime the 2 arrays\n",
    "    coast_indices_edge_nlon = coast_indices_edge[1]\n",
    "    coast_indices_edge_nlon[np.where(coast_indices_edge_nlon == 1)] = 319  # the 2nd column is 319\n",
    "    whole_nlat = np.concatenate((coast_indices[0], coast_indices_edge[0]))\n",
    "    whole_nlon = np.concatenate((coast_indices[1], coast_indices_edge_nlon))\n",
    "    coast_indices = (whole_nlat, whole_nlon)\n",
    "\n",
    "    # coastline mask in POP grid\n",
    "    coast_mask = np.zeros(kmt.shape)\n",
    "    for i in range(coast_indices[0].shape[0]):\n",
    "        j = coast_indices[0][i] # nlat\n",
    "        k = coast_indices[1][i] # nlon\n",
    "\n",
    "        coast_mask[j,k] = 1\n",
    "\n",
    "    coast_mask = coast_mask*ocean_mask\n",
    "    grid['coast_mask'] = xr.DataArray(data=coast_mask, dims=['nlat', 'nlon'])\n",
    "    \n",
    "    return grid, coast_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60969d96-5dc2-4de3-b1ce-248f44180ec2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get POP grid, and add coastline mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72160d1-5dfb-479e-b3e1-6a567835eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'POP_gx1v7'\n",
    "grid = pop_tools.get_grid(grid_name)\n",
    "grid, coast_indices = add_coast_mask(grid) # identify coastline indices in POP grid and add them to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee98b87-2da9-4259-85e0-3ae1350a8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlong = grid.TLONG.values\n",
    "tlat = grid.TLAT.values\n",
    "\n",
    "ocean_mask = (grid.KMT > 0).values # ocean mask as a numpy array\n",
    "coastal_mask = grid['coast_mask'].astype(np.int32)  # coastline mask, this is in the ocean, not on land"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e19af8-6d20-4188-9607-172ce4a26ebb",
   "metadata": {},
   "source": [
    "Idensity EEZ, 370km from the coastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e038d-c568-4465-a472-909b56f1840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points_within_square(i, j, grid_shape, tol=2):\n",
    "    \n",
    "    '''To find points' indices that are within a square of length 4, centered at a given point (i, j)'''\n",
    "    \n",
    "    m, n = grid_shape\n",
    "    # index of close points\n",
    "    ind_x = []\n",
    "    ind_y = []\n",
    "    \n",
    "    for x in range(max(0, i - tol*2), min(i + tol*2 + 1, m)):\n",
    "        for y in range(max(0, j - tol), min(j + tol + 1, n)):\n",
    "            #indices.append((x, y))\n",
    "            ind_x.append(x)\n",
    "            ind_y.append(y)\n",
    "    \n",
    "    return ind_x, ind_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da7a62-ffe6-4783-95c3-e31ba37844d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "threshold_distance = 370  # in kilometers\n",
    "\n",
    "# Create empty arrays for distances and region mask\n",
    "region_mask_eez = np.zeros_like(coastal_mask)\n",
    "region_mask_pools = np.zeros_like(coastal_mask)\n",
    "\n",
    "# loop each coastline grid index, and find points in the ocean that are close to it\n",
    "for i in range(coast_indices[0].shape[0]):\n",
    "    coast_nlat =  coast_indices[0][i]\n",
    "    coast_nlon =  coast_indices[1][i]\n",
    "    \n",
    "    #  1 coastal point coords\n",
    "    point = [tlong[coast_nlat, coast_nlon], tlat[coast_nlat, coast_nlon]]\n",
    "\n",
    "    # indices of the close points\n",
    "    close_points_x, close_points_y = find_points_within_square(coast_nlat, coast_nlon, grid.TLONG.shape, 5)\n",
    "    region_mask_pools[close_points_x, close_points_y] = 1 # the pools to select from\n",
    "    \n",
    "    # coordinates of the close points to be searched based on the distance\n",
    "    tlong_close = tlong[close_points_x, close_points_y]\n",
    "    tlat_close = tlat[close_points_x, close_points_y]\n",
    "    \n",
    "    # loop each caostal point, with a limited search domain, find EEZ\n",
    "    for j in range(len(close_points_x)):\n",
    "        if ocean_mask[close_points_x[j], close_points_y[j]]: # in the ocean\n",
    "            if gsw.distance([tlong_close[j], point[0]],  [tlat_close[j], point[1]]) <= threshold_distance*1000: # within distance threshold\n",
    "                region_mask_eez[close_points_x[j], close_points_y[j]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63b109-bf52-4df7-8931-9ea69d9e5048",
   "metadata": {},
   "source": [
    "You can also save the EEZ mask for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6cda7-470d-4a8b-af72-50e4b9d68866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid['eez_mask'] = xr.DataArray(data=region_mask_eez, dims=['nlat', 'nlon'])\n",
    "#grid.to_netcdf('./pop_grid_eez.nc', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8b616-be34-4a7d-a60a-858d99b7d18d",
   "metadata": {},
   "source": [
    "Selected EEZ grid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce74d8-e908-4206-9356-392b23ea4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tlong, tlat, c=region_mask_eez, s=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d377a3-e2c4-4279-b67a-b88d8acdb727",
   "metadata": {},
   "source": [
    "## Use K-means to generate polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462efc61-991b-4ca0-9d02-0a6a442ab228",
   "metadata": {},
   "source": [
    "Functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238ced5-378d-45f4-94c2-e15f6c605ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_longitudes(longitudes):\n",
    "    '''Convert longitudes from (0,360) to (-180,180)'''\n",
    "    \n",
    "    converted_longitudes = np.where(longitudes > 180, longitudes - 360, longitudes)\n",
    "    \n",
    "    return converted_longitudes\n",
    "\n",
    "def get_coords(mask_atlantic, convert_lon=True):\n",
    "    '''Given an ocean mask, return the selected lon(-180,180) and lat\n",
    "    convert_lon: to make longitude continuous, like Atlantic, but not Pacific\n",
    "    '''\n",
    "    \n",
    "    # Find the indices of the atlantic ocean in the mask, extract lon, lat\n",
    "    atlantic_indices = np.where(mask_atlantic == 1)\n",
    "\n",
    "    # we need to conver longitude from a range of 0 - 360, to a range of -180 to 180. You can put it back after find all pacthes\n",
    "    tlong_atlantic = tlong[atlantic_indices] \n",
    "    tlat_atlantic = tlat[atlantic_indices]\n",
    "    if convert_lon == True:\n",
    "        tlong_atlantic = convert_longitudes(tlong_atlantic)\n",
    "    \n",
    "    return tlong_atlantic, tlat_atlantic\n",
    "\n",
    "def get_polygons(mask_atlantic, num_polygons, convert_lon=True, save_ind=False):\n",
    "    \n",
    "    '''Given ocean mask, and the number of clusters\n",
    "    return Kmeans polygon_vertices, cluster_labels, cluster_centers\n",
    "    convert_lon: to make longitude continuous, like Atlantic, but not Pacific'''\n",
    "    \n",
    "    #the selected lon and lat\n",
    "    tlong_atlantic, tlat_atlantic = get_coords(mask_atlantic, convert_lon)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # construct data points\n",
    "    data_points = np.vstack((tlong_atlantic, tlat_atlantic)).T # shape of (13563, 2)\n",
    "\n",
    "    # Apply K-means clustering, run 30 times to get the best centroid\n",
    "    kmeans = KMeans(n_clusters=num_polygons, n_init=30)\n",
    "    kmeans.fit(data_points)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Initialize empty lists to store triangle vertices\n",
    "    polygon_vertices = [[] for _ in range(num_polygons)]\n",
    "    polygon_ind_inAtlanticPOP = [[] for _ in range(num_polygons)] # store the index in Atlantic POP grid\n",
    "\n",
    "    # Post-processing to form polygons\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        polygon_vertices[label].append(data_points[i])\n",
    "        polygon_ind_inAtlanticPOP[label].append(i)\n",
    "    polygon_vertices = np.array(polygon_vertices, dtype=\"object\")  # all clusters' coordinates\n",
    "    \n",
    "    if save_ind:\n",
    "        return polygon_vertices, polygon_ind_inAtlanticPOP, cluster_centers\n",
    "    else:\n",
    "        return polygon_vertices, cluster_centers\n",
    "\n",
    "\n",
    "def plot_polygons(polygon_vertices, cluster_centers, lon_extend, lat_extend, remove=[], region='Atlantic', center_lon=0, save=False):    \n",
    "        \n",
    "    '''PLot polygons, given:\n",
    "    polygon_vertices, cluster_centers: polygon coordinates, centers, \n",
    "    lon_extend, lat_extend: lon lat extends for plot\n",
    "    remove: indices in the polygon to remove. You will run with [] to see which ones you want to remove, and run again with, such as [45,46] \n",
    "    center_lon=0 for Atlantic, and 180 for Pacific\n",
    "    '''\n",
    "    \n",
    "    # remove some polygons \n",
    "    remove = [num - 1 for num in remove] # index in the plot is from 1\n",
    "    polygon_vertices = np.delete(polygon_vertices, remove)\n",
    "    cluster_centers = np.delete(cluster_centers, remove, axis=0) # remove rows\n",
    "\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=center_lon))\n",
    "    ax.set_extent([*lon_extend, *lat_extend], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # a list of colors\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    ind_color = np.arange(len(colors)) # 0- 9\n",
    "\n",
    "    # loop each cluster\n",
    "    for i in range(len(polygon_vertices)):\n",
    "        vertices = np.array(polygon_vertices[i])\n",
    "        if len(vertices) >= 3:\n",
    "            hull = ConvexHull(vertices) # get the indices of the periphery of a patch, for plotting purpose\n",
    "            polygon = list(vertices[i] for i in hull.vertices.tolist() )\n",
    "            polygon = np.array(polygon)\n",
    "\n",
    "            ax.plot(np.append(polygon[:,0], polygon[0,0]), np.append(polygon[:,1], polygon[0,1]), 'k-', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "            #ax.fill(polygon[:, 0], polygon[:, 1], alpha=0.2, transform=ccrs.PlateCarree())\n",
    "\n",
    "            ax.text(cluster_centers[i, 0]-1.8, cluster_centers[i, 1],str(i+1), fontsize=8, color='k', transform=ccrs.PlateCarree())\n",
    "            ax.scatter(vertices[:, 0], vertices[:, 1], c=colors[random.choice(ind_color)], s=1, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.stock_img()\n",
    "    ax.set_xticks(np.arange(lon_extend[0]+10, lon_extend[1], 30), crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(np.arange(lat_extend[0]+10, lat_extend[1], 20), crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "\n",
    "    ax.set_title(f'{region}, n={len(polygon_vertices)}')\n",
    "    \n",
    "    if save==True:\n",
    "        plt.savefig(f'./figures/{region}_{len(polygon_vertices)}polygons.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "def get_polygon_mask(tlong, mask_atlantic, polygon_ind_inAtlanticPOP):\n",
    "    '''Return a mask for the polygon, given its vertexes\n",
    "    tlong : POP grid\n",
    "    '''\n",
    "    \n",
    "    # Find the indices of the atlantic ocean in the mask, extract lon, lat\n",
    "    atlantic_indices = np.where(mask_atlantic == 1)\n",
    "    \n",
    "    a,b = tlong.shape\n",
    "    n = len(polygon_ind_inAtlanticPOP) # number of patches\n",
    "    \n",
    "    # polygon mask\n",
    "    polygon_mask = np.zeros((n,a,b))\n",
    "\n",
    "    for i in range(n):  \n",
    "        \n",
    "        # indices of the polygon points in the Atlantic subset\n",
    "        polygon_ind_inAtlanticPOP_54 = polygon_ind_inAtlanticPOP[i]\n",
    "\n",
    "        # indices of selected polygon points in the original POP grid\n",
    "        polygon_nlat = atlantic_indices[0][polygon_ind_inAtlanticPOP_54]\n",
    "        polygon_nlon = atlantic_indices[1][polygon_ind_inAtlanticPOP_54]\n",
    "        \n",
    "\n",
    "        #  assign 1s\n",
    "        for j in range(polygon_nlat.shape[0]):  # for each point in a polygon\n",
    "            polygon_mask[i, polygon_nlat[j], polygon_nlon[j]] = 1\n",
    "\n",
    "        if np.count_nonzero(polygon_mask[i]) != len(polygon_ind_inAtlanticPOP_54): # make sure the number of 1s in the mask == the number of vertexes in a patch\n",
    "            print(f'Polygon {i} has different amount of 1s from the number of vertexes in the patch!')\n",
    "    return polygon_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc2618-4ff8-4d13-8303-625567f10a75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define region domains\n",
    "\n",
    "Global ocean is divided into four domains (North Atlantic, North Pacific, South, Southern Ocean), which are further divided into 690 polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a3a4e-3e4e-49f3-9e0a-66727e99a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_range_mask(lat_min, lat_max):\n",
    "    '''Return a mask over a range of latitudes'''\n",
    "\n",
    "    region_mask_name = 'lat-range-basin'\n",
    "    region_mask = pop_tools.region_mask_3d('POP_gx1v7', region_mask_name)\n",
    "    keep = np.ones(region_mask.sizes['region']).astype(bool)\n",
    "    for i in range(region_mask.sizes[\"region\"]):\n",
    "        region_mask.data[i, :, :] = xr.where(\n",
    "            (region_mask[i, :, :] == 1.0) & (lat_min < grid.TLAT) & (grid.TLAT < lat_max), 1.0, 0.0\n",
    "        )\n",
    "        if not region_mask[i, :, :].any():\n",
    "            keep[i] = False\n",
    "\n",
    "    region_mask = region_mask[keep, :, :]\n",
    "    \n",
    "    return region_mask[0]\n",
    "\n",
    "lat_10S90N_mask = get_lat_range_mask(-10, 90)\n",
    "lat_10S75N_mask = get_lat_range_mask(-10, 75)\n",
    "lat_10S70N_mask = get_lat_range_mask(-10, 70)\n",
    "lat_60S0N_mask = get_lat_range_mask(-60, 0)\n",
    "lat_90S50S_mask = get_lat_range_mask(-90, -50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad2087-315e-4530-8e20-d3b6abb2f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3d = pop_tools.region_mask_3d(grid_name, mask_name='default')\n",
    "mask_atlantic =  mask3d.sel(region='Atlantic Ocean')*lat_10S90N_mask # Atlantic up to 10S\n",
    "mask_GIN =  mask3d.sel(region='GIN Seas')*lat_10S75N_mask # GIN Sea uo to 75N\n",
    "mask_LabSea =  mask3d.sel(region='Lab. Sea & Baffin Bay')*lat_10S70N_mask # Labrador Sea up t0 70N\n",
    "\n",
    "# N. Pacific\n",
    "mask_pacific =  mask3d.sel(region='Pacific Ocean')*lat_10S90N_mask # Pacific up to 10S\n",
    "\n",
    "# N. Atlantic\n",
    "mask_atlantic = np.logical_or(np.logical_or(mask_atlantic, mask_GIN), mask_LabSea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fee3f0-86aa-4f7f-a08d-e0b466f9c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_South_atlantic = mask3d.sel(region='Atlantic Ocean')*lat_60S0N_mask \n",
    "mask_South_pacific = mask3d.sel(region='Pacific Ocean')*lat_60S0N_mask \n",
    "mask_indian = mask3d.sel(region='Indian Ocean')\n",
    "mask_southern = mask3d.sel(region='Southern Ocean')*lat_60S0N_mask \n",
    "# get rid of the overlap\n",
    "overlap_atlantic = np.logical_and(mask_South_atlantic, mask_atlantic)\n",
    "overlap_pacific = np.logical_and(mask_South_pacific, mask_pacific)\n",
    "mask_South_atlantic = mask_South_atlantic - overlap_atlantic\n",
    "mask_South_pacific = mask_South_pacific - overlap_pacific\n",
    "\n",
    "# South\n",
    "mask_south_atl_pac = np.logical_or(mask_South_pacific, mask_South_atlantic)\n",
    "mask_south = np.logical_or(np.logical_or(mask_south_atl_pac, mask_indian), mask_southern)\n",
    "\n",
    "# Southern Ocean\n",
    "overlap = np.logical_and(mask_south, lat_90S50S_mask)\n",
    "mask_Southern_Ocean = np.logical_not(overlap)*lat_90S50S_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205bd0e-f2c4-456c-a310-33ec01ab5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 8})\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=210))\n",
    "ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n",
    "\n",
    "# selected coastline in POP grid\n",
    "ax.scatter(tlong[mask_atlantic==1], tlat[mask_atlantic==1], c='r', s=0.1, alpha=0.5, transform=ccrs.PlateCarree())\n",
    "ax.scatter(tlong[mask_pacific==1], tlat[mask_pacific==1], c='b', s=0.1, alpha=0.5, transform=ccrs.PlateCarree())\n",
    "ax.scatter(tlong[mask_south==1], tlat[mask_south==1], c='y', s=0.1, alpha=0.5, transform=ccrs.PlateCarree())\n",
    "ax.scatter(tlong[mask_Southern_Ocean==1], tlat[mask_Southern_Ocean==1], c='purple', s=0.1, alpha=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 180, 30), crs=ccrs.PlateCarree())\n",
    "ax.set_yticks(np.arange(-90, 90, 30), crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "ax.stock_img()\n",
    "\n",
    "ax.text(-175, 40, 'N. Pacific', fontsize=15, transform=ccrs.PlateCarree())\n",
    "ax.text(-50, 40, 'N. Atlantic', fontsize=15, transform=ccrs.PlateCarree())\n",
    "ax.text(-170, -40, 'South', fontsize=15, transform=ccrs.PlateCarree())\n",
    "ax.text(-178, -70, 'Southern Ocean',fontsize=15, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813f253-c3c2-44bf-b447-270a44980cc9",
   "metadata": {},
   "source": [
    "## Clustering to form polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92785f87-c796-4790-adb6-ae8bb8eaca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_extend = {'Atlantic': [-110, 30], 'Pacific': [90, 290], 'South': [-180, 180], 'Southern_Ocean': [-180, 180]}\n",
    "lat_extend = {'Atlantic': [-40, 80], 'Pacific': [-30,80], 'South': [-90, 50], 'Southern_Ocean': [-90, -50], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf92c1-35e2-4437-be2a-fe37c6057749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(mask_, num_poly, reg_name='Atlantic', convert_lon=False, cen_lon=180, close=False):\n",
    "    '''\n",
    "    Given target mask_, and number of polygons, generate the polygons and visualization\n",
    "    \n",
    "    Return: array of polygon masks\n",
    "    '''\n",
    "    polygon_vertices, polygon_ind_inAtlanticPOP, cluster_centers = get_polygons(mask_, num_poly, convert_lon=convert_lon, save_ind=True)\n",
    "    # plot polygons\n",
    "    plot_polygons(polygon_vertices, cluster_centers, lon_extend[reg_name], lat_extend[reg_name], remove=[], region=reg_name, center_lon=cen_lon, save=False)\n",
    "    # The end product of polygon masks\n",
    "    polygon_mask_EEZ = get_polygon_mask(tlong, mask_, polygon_ind_inAtlanticPOP)\n",
    "\n",
    "    if close == True:\n",
    "        plt.close()\n",
    "\n",
    "    return polygon_mask_EEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b27635-70a0-4525-a695-6c0041ffa45e",
   "metadata": {},
   "source": [
    "North Atlantic - 100 in EEZ and 50 in open ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a429b3-dd0e-4558-8143-292dc6fbb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_mask_EEZ_NAtlantic = visualization(mask_atlantic*region_mask_eez, 100, reg_name='Atlantic', convert_lon=True, cen_lon=0)\n",
    "polygon_mask_open_ocean_NAtlantic = visualization(mask_atlantic*np.logical_not(region_mask_eez), 50, reg_name='Atlantic', convert_lon=True, cen_lon=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713473ce-2454-4401-b5e9-466cd52bea34",
   "metadata": {},
   "source": [
    "North Pacific - 90 in EEZ and 110 in open ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eedd286-be10-4f45-bb56-10da898c99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_mask_EEZ_NPacific = visualization(mask_pacific*region_mask_eez, 90, reg_name='Pacific', convert_lon=False, cen_lon=180)\n",
    "polygon_mask_open_ocean_NPacific = visualization(mask_pacific*np.logical_not(region_mask_eez), 110, reg_name='Pacific', convert_lon=False, cen_lon=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1640b-d0e7-42c3-8d66-119acdaee17a",
   "metadata": {},
   "source": [
    "South - 120 in EEZ and 180 in open ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611b9dc-e593-440b-9e63-240de2b144b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_mask_EEZ_South = visualization(mask_south*region_mask_eez, 120, reg_name='South', convert_lon=False, cen_lon=180)\n",
    "polygon_mask_open_ocean_South = visualization(mask_south*np.logical_not(region_mask_eez), 180, reg_name='South', convert_lon=False, cen_lon=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aec9ce-0a23-4ad7-8d4f-d1d81d8c54b7",
   "metadata": {},
   "source": [
    "Southern Ocean - 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ce2f8-d1d9-40e0-83da-aac9b6cca498",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_mask_Southern_Ocean = visualization(mask_Southern_Ocean, 40, reg_name='Southern_Ocean', convert_lon=False, cen_lon=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc140b84-6f7c-4f07-9c79-3f9ca28fa301",
   "metadata": {},
   "source": [
    "**Check THE END PRODUCT OF POLYGON MASKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91b161-9a31-468b-972e-6e5ce34a03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_masks = [polygon_mask_EEZ_NAtlantic, polygon_mask_open_ocean_NAtlantic, polygon_mask_EEZ_NPacific, polygon_mask_open_ocean_NPacific, polygon_mask_EEZ_South, polygon_mask_open_ocean_South, polygon_mask_Southern_Ocean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6d301-c877-4e64-ba77-8ecf7bfb6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=210))\n",
    "ax.set_extent([-110,30, -40, 80], crs=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "\n",
    "# a list of colors\n",
    "colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "ind_color = np.arange(len(colors)) # 0- 9\n",
    "\n",
    "for arr_region_masks in arr_masks:\n",
    "    for i in range(len(arr_region_masks)):\n",
    "    \n",
    "        # plot polygon masks\n",
    "        index = np.where(arr_region_masks[i] == 1)\n",
    "        ax.scatter(tlong[index], tlat[index], c=colors[random.choice(ind_color)], s=1, alpha=0.8, transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xticks(np.arange(-180, 180, 60), crs=ccrs.PlateCarree())\n",
    "ax.set_yticks(np.arange(-90, 90, 30), crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941555ba-8d31-4753-a219-91b2ca37f54a",
   "metadata": {},
   "source": [
    "## Notes\n",
    "1. The clusters are slightly different each time you run it.\n",
    "2. You might want to get rid of some polygons, like the red one in father Noth of Canada.\n",
    "3. You might want to combine some nearby polygons if they are too small to be considered as individual polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d3410-8f06-4362-93bb-b940a7254303",
   "metadata": {},
   "source": [
    "# Fig. S4\n",
    "The end product used in this study to simulate OAE in global ocean is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761eb78-faa2-459d-9f5f-76dccdf77211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacific\n",
    "final_polygon_mask_pacific = np.load('./data/polygon_data/Pacific_final_polygon_mask.npy')\n",
    "final_polygon_vertices_pacific = np.load('./data/polygon_data/Pacific_final_polygon_vertices.npy', allow_pickle=True)\n",
    "cluster_centers_pacific = np.load('./data/polygon_data/Pacific_final_cluster_centers.npy', allow_pickle=True)\n",
    "\n",
    "# atlantic\n",
    "final_polygon_mask_atlantic = np.load('./data/polygon_data/Atlantic_final_polygon_mask.npy')\n",
    "final_polygon_vertices_atlantic = np.load('./data/polygon_data/Atlantic_final_polygon_vertices.npy', allow_pickle=True)\n",
    "cluster_centers_atlantic = np.load('./data/polygon_data/Atlantic_final_cluster_centers.npy', allow_pickle=True)\n",
    "\n",
    "# south\n",
    "final_polygon_mask_south = np.load('./data/polygon_data/South_final_polygon_mask_120EEZ_180openocean.npy')\n",
    "final_polygon_vertices_south = np.load('./data/polygon_data/South_final_polygon_vertices_120EEZ_180openocean.npy', allow_pickle=True)\n",
    "cluster_centers_south = np.load('./data/polygon_data/South_final_cluster_centers_120EEZ_180openocean.npy', allow_pickle=True)\n",
    "\n",
    "# southern ocean\n",
    "final_polygon_mask_SO = np.load('./data/polygon_data/Southern_Ocean_final_polygon_mask.npy')\n",
    "final_polygon_vertices_SO = np.load('./data/polygon_data/Southern_Ocean_final_polygon_vertices.npy', allow_pickle=True)\n",
    "cluster_centers_SO = np.load('./data/polygon_data/Southern_Ocean_final_cluster_centers.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90424a-050d-455e-839b-5402c075f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'POP_gx1v7'\n",
    "grid = pop_tools.get_grid(grid_name)\n",
    "tlong = grid.TLONG.values\n",
    "tlat = grid.TLAT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a30bf3-d215-485b-942e-8410a21906f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.rcParams.update({'font.size': 24})\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=208))\n",
    "ax.set_extent([0, 360, -90, 80], crs=ccrs.PlateCarree())\n",
    "ax.tick_params(axis='both', labelsize=24)\n",
    "ax.imshow(imread('./lightearth.jpg'),origin='upper', transform=ccrs.PlateCarree(), extent=[-180, 180, -90, 90])\n",
    "#ax.stock_img()\n",
    "\n",
    "# a list of colors\n",
    "colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "ind_color = np.arange(len(colors)) # 0- 9\n",
    "\n",
    "def plot_polygons(final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic, offset=0):\n",
    "    for i in range(len(final_polygon_mask_atlantic)):\n",
    "        vertices = np.array(final_polygon_vertices_atlantic[i])\n",
    "        # plot convex hull\n",
    "        if len(vertices) >= 3:\n",
    "            hull = ConvexHull(vertices) # get the indices of the periphery of a patch, for plotting purpose\n",
    "            polygon = list(vertices[i] for i in hull.vertices.tolist() )\n",
    "            polygon = np.array(polygon)\n",
    "\n",
    "            ax.plot(np.append(polygon[:,0], polygon[0,0]), np.append(polygon[:,1], polygon[0,1]), 'k-', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "        # plot polygon masks\n",
    "        index = np.where(final_polygon_mask_atlantic[i] == 1)\n",
    "        ax.scatter(tlong[index], tlat[index], c=colors[random.choice(ind_color)], s=1, alpha=0.6, transform=ccrs.PlateCarree())\n",
    "        ax.text(cluster_centers_atlantic[i, 0]-2, cluster_centers_atlantic[i, 1]-1, str(i+offset), fontsize=7, color='k', transform=ccrs.PlateCarree())\n",
    "\n",
    "plot_polygons(final_polygon_mask_atlantic, final_polygon_vertices_atlantic, cluster_centers_atlantic)\n",
    "plot_polygons(final_polygon_mask_pacific,final_polygon_vertices_pacific, cluster_centers_pacific, offset=150)\n",
    "plot_polygons(final_polygon_mask_south, final_polygon_vertices_south, cluster_centers_south, offset=150+200)\n",
    "plot_polygons(final_polygon_mask_SO, final_polygon_vertices_SO, cluster_centers_SO, offset=150+200+300)\n",
    "\n",
    "ax.set_xticks(np.arange(10, 400, 30), crs=ccrs.PlateCarree())\n",
    "ax.set_yticks(np.arange(-60, 100, 20), crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter) \n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# plt.savefig('./figures/Figure_S4.png', dpi=400, bbox_inches='tight')\n",
    "# plt.savefig('./figures/Figure_S4.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387afd1-0be5-4cf5-962a-1b70085bfd5d",
   "metadata": {},
   "source": [
    "# Fig. S5\n",
    "Distribution of polygon areas in EEZ and open ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3085c3c-1a8e-4066-a6be-01f16639206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_from_mask(mask_atl, centers_atl):\n",
    "    \n",
    "    mask_atl = xr.DataArray(mask_atl, dims=('region', 'nlat', 'nlon'), coords={'region': np.arange(0,mask_atl.shape[0])})\n",
    "    #mask_atl.attrs['mask_name'] = 'North_Atlantic_basin'\n",
    "    area_atl = mask_atl*grid.TAREA/(1e10) # km^2\n",
    "    \n",
    "    # sum of all areas\n",
    "    area_atl_sum = area_atl.sum(dim={'nlat', 'nlon'}) \n",
    "    # number of grid points\n",
    "    count_num = area_atl.where(area_atl != 0).count(dim={'nlat', 'nlon'})\n",
    "    \n",
    "    return area_atl_sum, count_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853a298-c049-42d9-84df-e8febe0553e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_atl, count_atl = get_area_from_mask(final_polygon_mask_atlantic, cluster_centers_atlantic)\n",
    "area_pac, count_pac = get_area_from_mask(final_polygon_mask_pacific, cluster_centers_pacific)\n",
    "area_south, count_south = get_area_from_mask(final_polygon_mask_south, cluster_centers_south)\n",
    "area_SO, count_SO = get_area_from_mask(final_polygon_mask_SO, cluster_centers_SO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a219aba-11e0-4a5f-8cf9-9e5134db6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_EEZ = np.concatenate((area_atl[:100].values, area_pac[:90].values, area_south[:120].values))\n",
    "area_open_ocean = np.concatenate((area_atl[100:].values, area_pac[90:].values, area_south[120:].values, area_SO.values))\n",
    "\n",
    "center_EEZ = np.concatenate((cluster_centers_atlantic[:100], cluster_centers_pacific[:90], cluster_centers_south[:120]))\n",
    "center_open_ocean = np.concatenate((cluster_centers_atlantic[100:], cluster_centers_pacific[90:], cluster_centers_south[120:], cluster_centers_SO))\n",
    "\n",
    "count_EEZ = np.concatenate((count_atl[:100], count_pac[:90], count_south[:120]))\n",
    "count_open_ocean = np.concatenate((count_atl[100:], count_pac[90:], count_south[120:], count_SO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e84c79-489e-4ca3-9559-cec087824eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1.5, 1])  # Adjust the width ratios as needed\n",
    "\n",
    "ax = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1])\n",
    "\n",
    "# histogram\n",
    "bins=np.linspace(0, 1.1e6, 20)\n",
    "ax1.hist(area_EEZ, bins=bins, alpha=0.6, label='EEZ', color='C1')\n",
    "ax1.hist(area_open_ocean, bins=bins, alpha=0.6, label='Open Ocean', color='C0')\n",
    "\n",
    "# scatter\n",
    "ax.scatter(center_EEZ[:, 1], area_EEZ, s=25, marker='o', facecolors='C1', edgecolors='C1', label='EEZ')\n",
    "ax.scatter(center_open_ocean[:, 1], area_open_ocean, s=25, marker='o', facecolors='C0', edgecolors='C0', label='Open Ocean')\n",
    "\n",
    "FONTSIZE=6\n",
    "ax.set_xlabel('Latitude (˚N)')      \n",
    "ax.set_ylabel('Patch area ($km^2$)')      \n",
    "\n",
    "ax1.set_xlabel('Patch area ($km^2$)')      \n",
    "ax1.set_ylabel('Frequency')      \n",
    "\n",
    "def modify(ax):\n",
    "    ax.tick_params(axis='x')\n",
    "    ax.tick_params(axis='y')\n",
    "    \n",
    "modify(ax)\n",
    "modify(ax1)\n",
    "\n",
    "ax.legend()               \n",
    "ax1.legend()    \n",
    "\n",
    "ax.text(-95, 1.2e6, 'a', weight='bold',)\n",
    "ax1.text(-0.3e6, 129, 'b', weight='bold',)\n",
    "\n",
    "# plt.savefig('./figures/Figure_S5.png', dpi=300, bbox_inches='tight')\n",
    "# plt.savefig('./figures/Figure_S5.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d766183-e3a1-4d47-a362-9b30badc537a",
   "metadata": {},
   "source": [
    "## Numbers in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7faf1-a49b-4149-b5d1-07262404a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(area_EEZ), np.max(area_EEZ), np.min(area_open_ocean), np.max(area_open_ocean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1656514-ab95-44dc-aed3-8c9fea1969c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min value: {np.min(area_EEZ):.2e}\")\n",
    "print(f\"Max value: {np.max(area_open_ocean):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579969b-0a01-48e6-b793-9762cd6bde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many ships\n",
    "# one ship can do 5000 mol/s\n",
    "area_min = np.min(area_EEZ) # km^2\n",
    "area_max = np.max(area_open_ocean) # km^2\n",
    "\n",
    "ALK_rate = 10 # mol/m2/yr\n",
    "ALK_rate / 365/86400 / 5000 * area_min * 1e6, ALK_rate / 365/86400 / 5000 * area_max * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d38fba-cc64-4fef-a469-6f5c7e32d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total ALK in the first month\n",
    "alk_min = area_min * 1e6 * ALK_rate / 12 \n",
    "alk_max = area_max * 1e6 * ALK_rate / 12 \n",
    "\n",
    "print(f\"Min value: {np.min(alk_min):.2e}\")\n",
    "print(f\"Min value: {np.min(alk_max):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8c7f6-c13a-4d26-b7b7-39eaee67bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mol/s\n",
    "print(f\"Min value: {np.min(alk_min)/30/86400:.2e}\")\n",
    "print(f\"Min value: {np.min(alk_max)/30/86400:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b73400-1bba-4155-b22a-732921ef464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of ships\n",
    "print(f\"Min value: {np.min(alk_min)/30/86400/5000:.2e}\")\n",
    "print(f\"Min value: {np.min(alk_max)/30/86400/5000:.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
