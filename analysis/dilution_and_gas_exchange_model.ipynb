{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGb8o0XFB9rS"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as colors\n",
    "from glob import glob\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.MatplotlibDeprecationWarning)\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "\n",
    "import pop_tools\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K2qyoub0dB1"
   },
   "outputs": [],
   "source": [
    "path=\"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsgKD3sM_-2u"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions (hidden)\n",
    "def angle_mean(a): # calculate average on a circle\n",
    "  xbar = np.mean(np.cos(a*np.pi/180))\n",
    "  ybar = np.mean(np.sin(a*np.pi/180))\n",
    "  return math.atan2(ybar,xbar)*180.0/np.pi\n",
    "def deg_to_dms(deg):\n",
    "  d = int(deg)\n",
    "  md = abs(deg - d) * 60\n",
    "  m = int(md)\n",
    "  return [d, int(md), (md - m) * 60]\n",
    "def format_lat(lat):\n",
    "  d,m,s = deg_to_dms(lat)\n",
    "  return \"%d°%s\"%(abs(d),\"N\" if d>0 else \"S\")\n",
    "def format_lng(lng):\n",
    "  d,m,s = deg_to_dms(lng)\n",
    "  return \"%d°%s\"%(abs(d),\"E\" if d>0 else \"W\")\n",
    "#  return \"%d°%s=%f,%f\"%(abs(d),\"E\" if d>0 else \"W\", lng, d)\n",
    "def format_latlng(lat,lng):\n",
    "  return \"%s %s\"%(format_lat(lat), format_lng(lng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQRe7nv3G5c7"
   },
   "outputs": [],
   "source": [
    "all_curves = xr.open_dataset(f'{path}/all_curves_global.nc', decode_times=False)\n",
    "all_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zE13Ix3xG7aW"
   },
   "outputs": [],
   "source": [
    "REGIONS = all_curves.dims[\"region\"]\n",
    "NPOLYGONS = [int(np.sum(~np.isnan(all_curves.isel(region=r, season=0, time=0).frac_ALK_excess_surf.values)))\n",
    "             for r in range(REGIONS)]\n",
    "SEASONS=4\n",
    "\n",
    "# Read polygon masks\n",
    "#Pacific_polygon_masks = xr.open_dataset(f'{path}/polygon_data/pacific_polygon_masks.nc')\n",
    "#Atlantic_polygon_masks = xr.open_dataset(f'{path}/atlantic_polygon_masks.nc')\n",
    "#South_polygon_masks = xr.open_dataset(f'{path}/south_polygon_masks.nc')\n",
    "#Southern_polygon_masks = xr.open_dataset(f'{path}/southern_ocean_polygon_masks.nc')\n",
    "\n",
    "Pacific_polygon_masks = np.load('./data/polygon_data/Pacific_final_polygon_mask.npy')\n",
    "Atlantic_polygon_masks = np.load('./data/polygon_data/Atlantic_final_polygon_mask.npy')\n",
    "South_polygon_masks = np.load('./data/polygon_data/South_final_polygon_mask_120EEZ_180openocean.npy')\n",
    "Southern_polygon_masks = np.load('./data/polygon_data/Southern_Ocean_final_polygon_mask.npy')\n",
    "\n",
    "print(final_polygon_mask_pacific.shape)\n",
    "\n",
    "POLYGON_MASKS = [Pacific_polygon_masks, Atlantic_polygon_masks, South_polygon_masks, Southern_polygon_masks]\n",
    "DATALEN = 180\n",
    "\n",
    "TOPLAYER_DEPTH=10 #meters\n",
    "\n",
    "print(\"REGIONS: \", REGIONS)\n",
    "print(\"SEASONS:\", SEASONS)\n",
    "print(\"NPOLYGONS: \", NPOLYGONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEyUMdMClOwf"
   },
   "outputs": [],
   "source": [
    "# Read POP grid\n",
    "# nlat: 384 nlon: 320\n",
    "grid = pop_tools.get_grid('POP_gx1v7')[['TAREA', 'KMT', 'TLAT', 'TLONG', 'REGION_MASK']]\n",
    "grid.to_netcdf(path=\"~/pop_grid_gx1v7.nc\")\n",
    "\n",
    "#grid = xr.open_dataset(f'{path}/pop_grid_gx1v7.nc', decode_times=False)\n",
    "tlong = grid.TLONG.values\n",
    "tlat = grid.TLAT.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fa90VLegD7uW"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "polygon_mask_map = {}\n",
    "for r in range(len(NPOLYGONS)):\n",
    "    num_polygon = NPOLYGONS[r]\n",
    "    polygon_masks = POLYGON_MASKS[r]\n",
    "    for p in range(num_polygon):\n",
    "      mask = polygon_masks[p]\n",
    "\n",
    "      index = np.where(mask > 0)\n",
    "      _tlat=tlat[mask>0]\n",
    "      _tlong=tlong[mask>0]\n",
    "      polygon_mask_map[(r,p)] = {\"mask\":mask,\n",
    "                                 \"index\":index,\n",
    "                                 \"tlat\": _tlat,\n",
    "                                 \"tlng\": _tlong,\n",
    "                                 \"mean_latlng\":(np.mean(_tlat),\n",
    "                                            angle_mean(_tlong))\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cg69wUsNcPFh"
   },
   "outputs": [],
   "source": [
    "indexmap = np.full(tlong.shape, np.nan)\n",
    "for r in range(len(NPOLYGONS)):  # 0-Pacific or 1-Atlantic\n",
    "    num_polygon = NPOLYGONS[r]\n",
    "    polygon_masks = POLYGON_MASKS[r]\n",
    "    for p in range(num_polygon):  # number of polygons\n",
    "      mask = polygon_masks[p]\n",
    "      index = np.where(mask > 0)\n",
    "      indexmap[:,:][index] = (mask * (r*1E6+p))[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMRUVrJ90zMp"
   },
   "source": [
    "# Load $\\eta_{max}$ data from carbonate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2fd4RQ1FZnR"
   },
   "outputs": [],
   "source": [
    "dDIC_dALK_all = xr.open_dataset('./data/dDIC_dALK_all.nc', decode_times=False)\n",
    "eta_max_data = np.vstack([dDIC_dALK_all.ULAT.mean('nlon'),\n",
    "                          dDIC_dALK_all.mean('nlon').mean('time').to_array()[0] ])\n",
    "eta_max_data = eta_max_data[:,~np.isnan(eta_max_data[1])] # get rid of nan points\n",
    "eta_max_data = eta_max_data[:,eta_max_data[0].argsort()] # ensure strict ordering in x\n",
    "eta_max_data = np.pad(eta_max_data, ( (0,0), (1,1) ), mode=\"edge\")\n",
    "eta_max_data[0,0] = -90\n",
    "eta_max_data[0,-1] = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMKKZZEV1M32"
   },
   "outputs": [],
   "source": [
    "import  scipy.interpolate\n",
    "\n",
    "eta_max_func_raw = scipy.interpolate.PchipInterpolator(eta_max_data[0], eta_max_data[1], axis=0, extrapolate=True)\n",
    "latrange = np.linspace(-180,180)\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "  return 1/(sigma*np.sqrt(2*np.pi)) * np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "\n",
    "kernel = gaussian(latrange, 0 , 20)\n",
    "kernel /= np.sum(kernel)\n",
    "smoothed =  np.convolve(kernel, eta_max_func_raw(latrange), mode=\"same\" )\n",
    "eta_max_func_smoothed = scipy.interpolate.PchipInterpolator(latrange, smoothed, axis=0, extrapolate=False)\n",
    "\n",
    "# calculate surface weighted average\n",
    "latrange_80_80 = np.linspace(-80,80)\n",
    "waverage = np.sum(eta_max_func_raw(latrange_80_80)*np.cos(latrange_80_80/180*np.pi))/np.sum(np.cos(latrange_80_80/180*np.pi))\n",
    "\n",
    "plt.plot(eta_max_data[0], eta_max_data[1], label=\"raw data\", marker=\"o\")\n",
    "plt.plot(latrange, eta_max_func_raw(latrange), label=\"\")\n",
    "plt.plot(latrange, eta_max_func_smoothed(latrange), label=\"kernel smoothed\", ls=\"dashed\")\n",
    "plt.axhline(waverage, ls=\"dotted\", label=\"Global area weighted average\")\n",
    "plt.xlim(-90,90)\n",
    "plt.ylim(0.75,0.95)\n",
    "plt.ylabel('$\\partial[DIC]/\\partial [Alk]$');\n",
    "plt.xlabel('Latitude')\n",
    "plt.legend(loc=\"upper center\")\n",
    "\n",
    "eta_max_func = eta_max_func_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kziQTOnI4whU"
   },
   "source": [
    "# Set up two-plume box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGGfUl3IZgzF"
   },
   "outputs": [],
   "source": [
    "def equilibration_curve(t, eta_max, ta, tl, tb):\n",
    "    '''\n",
    "    t: time\n",
    "    eta_max: initial condition (this doubles as intrinsic \"max\" efficiency, ~0.81)\n",
    "    ta: apparent e-folding time of gas exchange early reservoir\n",
    "    tl: e-folding time of transfer to second reservoir\n",
    "    tb: apparent e-folding time of gas exchange for the late reservoir\n",
    "    '''\n",
    "    tal = 1.0/(1/ta+1/tl)\n",
    "    Q = (tl*ta - tl*tb)/(ta*tl - tb*tl - ta*tb)\n",
    "    return eta_max * (1\n",
    "            -  Q * np.exp(-t/tal)\n",
    "            -  (1-Q) * np.exp(-t/tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1FjNBsatzvg"
   },
   "outputs": [],
   "source": [
    "t=np.linspace(0,15*12,100)\n",
    "plt.plot(t, equilibration_curve(t, 0.85, 10,  20,  20))\n",
    "plt.plot(t, equilibration_curve(t, 0.85, 10,  20, 200))\n",
    "plt.plot(t, equilibration_curve(t, 0.85,  3,  80,  40))\n",
    "plt.title(\"Example equilibration curves\")\n",
    "plt.ylabel(\"$\\eta(t)$\")\n",
    "plt.xlabel(\"t (months)\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXEnOqkRNJS3"
   },
   "outputs": [],
   "source": [
    "def dilution_curve(t, dila, tl, dilb, pulsewidth = 1.0):\n",
    "  A = dila\n",
    "  B = dilb\n",
    "\n",
    "  # if the pulse was instantaneous, the result is\n",
    "  if pulsewidth==0.0:\n",
    "    result = (A-B)*np.exp(-t/tl) + B\n",
    "    return result\n",
    "\n",
    "  # But with a finite pulse length we have a convolution between the\n",
    "  # underlying exponential and the wide pulse:\n",
    "\n",
    "  # A correction factor due to the convolution with the finite-width pulse\n",
    "  correction_factor = (tl/pulsewidth)*(np.exp(pulsewidth/tl)-1)\n",
    "  result = np.where(t<pulsewidth,\n",
    "     (A-B)*(tl/pulsewidth)*(1-np.exp(-t/tl))        + (t/pulsewidth)*B,\n",
    "     (A-B)*correction_factor*np.exp(-t/tl)          +                B)\n",
    "\n",
    "  return result\n",
    "\n",
    "t=np.linspace(0.0,15*12,500)\n",
    "plt.plot(t, dilution_curve(t, dila=1/10, tl=40, dilb=1/50))\n",
    "plt.plot(t, dilution_curve(t, dila=1/20, tl=40, dilb=1/50))\n",
    "plt.plot(t, dilution_curve(t, dila=1/20, tl=10, dilb=1/100))\n",
    "plt.title(\"Examples: Dilution of excess surface alkalinity\")\n",
    "plt.ylabel(\"$\\mu(t)$\")\n",
    "plt.xlabel(\"t (months)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYNxWOyZhdbh"
   },
   "outputs": [],
   "source": [
    "# Simultaneously fit the equilibration curve and the surface dilution curve to the above functions for a given\n",
    "# polygon, represented by a tuple of three indices: r,s and p.\n",
    "def fit_simultaneous(r,s,p, N_skip = 6,\n",
    "                     local_eta_max = None,\n",
    "                     show=False, only_data=False, figaxs=None):\n",
    "  assert r<REGIONS\n",
    "  assert s<SEASONS\n",
    "  assert p<NPOLYGONS[r]\n",
    "  eq_y_data_raw = all_curves.isel(region=r, season=s, polygon=p).OAE_efficiency[3*s:3*s+DATALEN]\n",
    "  eq_x_data_raw = np.arange(0,len(eq_y_data_raw)) + 0.5\n",
    "  eq_y_data = eq_y_data_raw[N_skip:]\n",
    "  eq_x_data = eq_x_data_raw[N_skip:]\n",
    "\n",
    "  dil_y_data_raw = all_curves.isel(region=r, season=s, polygon=p).frac_ALK_excess_surf.values[3*s:3*s+DATALEN]\n",
    "  dil_x_data_raw =  np.arange(0,len(dil_y_data_raw)) + 0.5 # t_data is relative to start of injection period\n",
    "  dil_y_data = dil_y_data_raw[N_skip:]\n",
    "  dil_x_data = dil_x_data_raw[N_skip:]\n",
    "\n",
    "  if local_eta_max is None:\n",
    "    lat = polygon_mask_map[(r,p)][\"mean_latlng\"][0]\n",
    "    #local_eta_max = eta_max_func(lat)\n",
    "    local_eta_max = eta_max_func_smoothed(lat)\n",
    "\n",
    "  # Define the cost function\n",
    "  def cost_function_eq(params, eq_x, eq_y, dil_x, dil_y):\n",
    "    eta_max, ta, tl, tb, dila, dilb = params\n",
    "    return (np.sum((eq_y - equilibration_curve(eq_x, eta_max, ta, tl, tb))**2)\n",
    "            + 0.2*np.exp(20*np.clip(ta-tb,-1000,1)))  ## A penalty factor to prevent tb << ta\n",
    "\n",
    "  def cost_function_dil(params, eq_x, eq_y, dil_x, dil_y):\n",
    "    eta_max, ta, tl, tb, dila, dilb = params\n",
    "    return np.sum((dil_y - dilution_curve(dil_x, dila,  tl,  dilb))**2)\n",
    "\n",
    "  def cost_function(params, eq_x, eq_y, dil_x, dil_y):\n",
    "    relative_cost = 1.0\n",
    "    return (cost_function_eq(params, eq_x, eq_y, dil_x, dil_y) +\n",
    "            cost_function_dil(params, eq_x, eq_y, dil_x, dil_y)*relative_cost )\n",
    "\n",
    "  bounds=[[ 0.79,  2,     6,     6, 0.001, 0.001],\n",
    "          [ 0.88, 90,  1000, 10000,   1.0,   1.0]]\n",
    "  initial1 = [  np.clip(0.84, bounds[0][0],bounds[1][0]),  # etamax\n",
    "                np.clip(10,   bounds[0][1],bounds[1][1]),   # ta\n",
    "                np.clip(15,   bounds[0][2],bounds[1][2]),   # tl\n",
    "                np.clip(25,  bounds[0][3],bounds[1][3]),    # tb\n",
    "                np.clip(0.2 , bounds[0][4],bounds[1][4]),   # dila\n",
    "                np.clip(0.05, bounds[0][5],bounds[1][5]),   # dilb\n",
    "               ]\n",
    "  # Alternative set of starting conditions that sometimes find a better fit\n",
    "  initial2 = [  np.clip(0.88, bounds[0][0],bounds[1][0]),   # etamax\n",
    "                np.clip(20,   bounds[0][1],bounds[1][1]),   # ta\n",
    "                np.clip(40,   bounds[0][2],bounds[1][2]),   # tl\n",
    "                np.clip(125,  bounds[0][3],bounds[1][3]),   # tb\n",
    "                np.clip(0.2 , bounds[0][4],bounds[1][4]),   # dila\n",
    "                np.clip(0.05, bounds[0][5],bounds[1][5]),   # dilb\n",
    "               ]\n",
    "\n",
    "  ## Two attempts to fit it. If initial conditions dont give a good\n",
    "  ## answer, try initial2 in case it converges to a lower result.\n",
    "  results = []\n",
    "  for attempt in range(2):\n",
    "\n",
    "    #         etamax,              ta,    tl,    tb,   dila,  dilb\n",
    "    bounds=[[ 0.79,  2,     6,     6, 0.001, 0.001],\n",
    "            [ 0.88, 90,  1000, 10000,   1.0,  1.0]]\n",
    "    initial = [initial1, initial2][attempt]\n",
    "\n",
    "    bounds[0][0]=min(0.9, max(0.79, local_eta_max-0.01))\n",
    "    bounds[1][0]=min(0.9, max(0.79, local_eta_max+0.01))\n",
    "    initial[0] = local_eta_max\n",
    "\n",
    "    result = minimize(fun=cost_function,\n",
    "           x0 = initial,\n",
    "           bounds=[(a,b) for a,b in np.array(bounds).T],\n",
    "           method=\"L-BFGS-B\",\n",
    "           args=(eq_x_data, eq_y_data, dil_x_data, dil_y_data))\n",
    "    etamax, ta, tl, tb, dila, dilb = result.x\n",
    "\n",
    "    results.append(result)\n",
    "    if result.fun < 0.05:\n",
    "      break # abort if the fit is good enough\n",
    "\n",
    "  if len(results) > 1:\n",
    "    result = results[0] if results[0].fun < results[1].fun else results[1]\n",
    "\n",
    "  if not show:\n",
    "    return etamax, ta, tl, tb, dila, dilb, result.fun,\n",
    "\n",
    "  print(\"%1d,%1d,%3d,\"%(r,s,p), \": %5f : %.3f %5.1f %5.1f %5.3f %5.3f %5.3f\"%(result.fun, etamax, ta, tl, tb, dila, dilb))\n",
    "  firstplot = True if figaxs is None else False\n",
    "  fig, axs = plt.subplots(1,2, figsize=(10, 4)) if figaxs is None else figaxs\n",
    "\n",
    "  # Plot the dilution\n",
    "  ax1 = axs[0]\n",
    "  ax1.plot(eq_x_data_raw, dil_y_data_raw, c=\"blue\", ls=\"dotted\",\n",
    "           lw=3, label=\"Data, loc: %d, %d, %d, %s\"%(r,s,p,format_latlng(*polygon_mask_map[(r,p)][\"mean_latlng\"])))\n",
    "  ax1.plot(eq_x_data_raw[1:], dilution_curve(eq_x_data_raw[1:], dila,  tl,  dilb), c=\"black\",\n",
    "          label=\"Fit, Nskip=%d, err=%0.5f \\n$dil_{a}$=%.4fm, $\\\\tau_\\ell$=%.1fmo, $dil_{b}$=%.4fm\"%(\n",
    "              N_skip, result.fun, dila,  tl,  dilb))\n",
    "  ax1.set_ylim(0.0001,max(0.1, np.max(dil_y_data_raw)))\n",
    "  ax1.legend(loc=\"upper right\")\n",
    "  ax1.set_ylabel(\"Fraction Alk ($A_{0}$)\")\n",
    "  ax1.set_xlabel(\"time/mo\")\n",
    "\n",
    "  # Plot the equilibration\n",
    "  ax=axs[1]\n",
    "  ax.plot(eq_x_data_raw, eq_y_data_raw,  c=\"red\", ls=\"dotted\", lw=3, label=None)\n",
    "  if not only_data:\n",
    "    ax.plot(eq_x_data_raw, equilibration_curve(eq_x_data_raw, etamax, ta, tl, tb),\n",
    "             label = r\"%s: $\\eta$=%.3f $\\tau_a$=%.1fm \" \"\\n\" r\"$\\tau_\\ell$=%.1fm,  $\\tau_b$=%.1fm\"%([\"Jan\",\"Apr\",\"Jul\",\"Oct\"][s],etamax, ta, tl, tb),\n",
    "             c=\"black\")\n",
    "  ax.set_ylim(0,1.0)\n",
    "  ax.legend(loc='upper right')\n",
    "  ax.set_ylabel(\"$\\eta(t)$\")\n",
    "  ax.set_xlabel(\"time/mo\")\n",
    "\n",
    "  return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scsYNGBnMw_5"
   },
   "outputs": [],
   "source": [
    "def plot_location(r,s,p,  ax, no_left=False, no_right=False, label=\"\"):\n",
    "  assert r<REGIONS\n",
    "  assert s<SEASONS\n",
    "  assert p<NPOLYGONS[r]\n",
    "  etamax, ta, tl, tb, dila, dilb, err = fit_simultaneous(r,s,p,  show=False)\n",
    "  eq_y_data_raw = all_curves.isel(region=r, season=s, polygon=p).OAE_efficiency[3*s:3*s+DATALEN]\n",
    "  eq_x_data_raw = np.arange(0,len(eq_y_data_raw)) + 0.5\n",
    "  dil_y_data_raw = all_curves.isel(region=r, season=s, polygon=p).frac_ALK_excess_surf.values[3*s:3*s+DATALEN]\n",
    "  dil_x_data_raw =  np.arange(0,len(dil_y_data_raw)) + 0.5 # t_data is relative to start of injection period\n",
    "\n",
    "  # Plot the dilution\n",
    "  ax2 = ax.twinx()\n",
    "  ax1 = ax\n",
    "\n",
    "  # A virtual line that's just there to get the location traits into the lagend\n",
    "  ln0 = ax1.plot(eq_x_data_raw[1:],eq_x_data_raw[1:]*0, alpha=0.0, c=\"w\",\n",
    "                 label=\"%s, %s, %s\"%(label, [\"Jan\", \"Apr\", \"Jul\", \"Oct\"][s],\n",
    "                                 format_latlng(*polygon_mask_map[(r,p)][\"mean_latlng\"])))\n",
    "\n",
    "  ax1.plot(eq_x_data_raw[1:], dil_y_data_raw[1:], c=\"blue\", ls=\"dotted\",\n",
    "           lw=3, label=\"Data, loc: %d, %d, %d, %s\"%(r,s,p,format_latlng(*polygon_mask_map[(r,p)][\"mean_latlng\"])))\n",
    "  ln1 = ax1.plot(eq_x_data_raw[1:], dilution_curve(eq_x_data_raw[1:], dila,  tl,  dilb), c=\"blue\",\n",
    "          label=\"$\\\\mu$(t): $\\\\mu_{a}$=%.3f, $\\\\tau_\\ell$=%.fm, $\\\\mu_{b}$=%.3f\"%(dila,  tl,  dilb))\n",
    "  ax1.set_ylim(0.0001,0.20)\n",
    "  ax1.set_yticks([0.00, 0.02,0.04,0.06,0.08,0.10,0.12,0.14,0.16])\n",
    "\n",
    "  if not no_left:\n",
    "    ax1.set_ylabel(\"Frac. Surface Alk, $\\\\mu(t)$\", color='b')\n",
    "  #else:\n",
    "  #  ax1.set_yticklabels(\"\")\n",
    "\n",
    "  ax1.spines['left'].set_color('blue')\n",
    "  ax1.tick_params(axis='y', colors='blue')\n",
    "  ax1.yaxis.label.set_color('blue')\n",
    "\n",
    "  # -----------------------\n",
    "  # Plot the equilibration\n",
    "  ax2.plot(eq_x_data_raw, eq_y_data_raw,  c=\"red\", ls=\"dotted\", lw=3, label=None)\n",
    "  ln2 = ax2.plot(eq_x_data_raw, equilibration_curve(eq_x_data_raw, etamax, ta, tl, tb),\n",
    "             label = r\"$\\eta(t)$: $\\eta_{max}$=%.2f $\\tau_a$=%.fm  $\\tau_b$=%.fm\"%(etamax, ta, tb),\n",
    "             c=\"red\")\n",
    "  ax2.set_ylim(0,1.4)\n",
    "  ax2.set_yticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "  lns = ln0+ln2+ln1\n",
    "  labs = [l.get_label() for l in lns]\n",
    "  ax.legend(lns, labs, loc=\"upper right\") #, mode=\"expand\", bbox_to_anchor=(0.0, 0.0, 1.0, 1.0))\n",
    "\n",
    "  if not no_right:\n",
    "    ax2.set_ylabel(\"$\\eta(t)$  [mol/mol]\", color='r')\n",
    "\n",
    "  ax2.spines['left'].set_color('red')\n",
    "  ax2.tick_params(axis='y', colors='red')\n",
    "  ax2.yaxis.label.set_color('red')\n",
    "  ax2.set_xlabel(\"time/mo\")\n",
    "  ax2.set_xticks(np.arange(0,8)*24)\n",
    "  ax2.xaxis.set_minor_locator(MultipleLocator(12))\n",
    "\n",
    "  return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geHqmtVJoObz"
   },
   "outputs": [],
   "source": [
    "def get_average_equilibration(r,s0,p, month=60):\n",
    "  assert r<REGIONS\n",
    "  assert p<NPOLYGONS[r]\n",
    "  y_data=[]\n",
    "  for s in range(SEASONS):\n",
    "    y_data.append(all_curves.isel(region=r, season=s, polygon=p).OAE_efficiency[3*s:3*s+DATALEN])\n",
    "  y_data = np.vstack(y_data)\n",
    "  stddev = np.sqrt(np.var(y_data,axis=0))\n",
    "  mean = np.mean(y_data,axis=0)\n",
    "  return mean[month], stddev[month], y_data[s0][month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvDMDAvsNFdC"
   },
   "outputs": [],
   "source": [
    "get_average_equilibration(3,0,1, month=60-1)\n",
    "all_curves.isel(region=3, polygon=1).OAE_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrgNw6Zypvlw"
   },
   "outputs": [],
   "source": [
    "def fit_all_data(filename='~/simul_fit_horizontal.h5', regions=None, seasons=None, maxpoly=10000):\n",
    "  columns=['r','s', 'p',\n",
    "           'eta_max', 'ta', 'tl', 'tb', 'dila', 'dilb', 'err', 'lat', 'lng',\n",
    "           'mean24', 'stddev24', 'eta24',\n",
    "           'mean60', 'stddev60', 'eta60',\n",
    "           'mean180', 'stddev180', 'eta180']\n",
    "  dfs = []\n",
    "  for r in (regions or range(REGIONS)):\n",
    "    print(\"Region: \", r)\n",
    "    for s in (seasons or range(SEASONS)):\n",
    "      print(\" Season: \", s)\n",
    "      for p in range(min(maxpoly, NPOLYGONS[r])):\n",
    "        if p%20==0: print(\"  Polygon: \", p)\n",
    "        eta_max, ta, tl, tb, dila, dilb, err = fit_simultaneous(r, s, p,  show=False)\n",
    "\n",
    "        mean24, stddev24, eta24  = get_average_equilibration(r,s,p, month=24-1)\n",
    "        mean60, stddev60, eta60 = get_average_equilibration(r,s,p, month=60-1)\n",
    "        mean180, stddev180, eta180 = get_average_equilibration(r,s,p, month=180-1)\n",
    "\n",
    "        # calc avg lat and long of polygon\n",
    "        lat = polygon_mask_map[(r,p)][\"mean_latlng\"][0]\n",
    "        lng = polygon_mask_map[(r,p)][\"mean_latlng\"][1]\n",
    "        dfs.append(pd.DataFrame([[r, s, p,  eta_max, ta, tl, tb, dila, dilb, err, lat, lng,\n",
    "                                  mean24, stddev24, eta24,\n",
    "                                  mean60, stddev60, eta60,\n",
    "                                  mean180, stddev180, eta180]],\n",
    "                                columns=columns))\n",
    "\n",
    "  df = pd.concat(dfs)\n",
    "  df = df.set_index(['r','s','p'], drop=False)\n",
    "  if filename: df.to_hdf(filename,'residence_times')\n",
    "  return df\n",
    "\n",
    "qdf = fit_all_data(filename='~/simul_fit.h5', regions=[1], maxpoly=1)\n",
    "qdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn8zDtSaBS35"
   },
   "source": [
    "# SLOW: Fit all polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch5sNgww4iK8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "def run_job(input_index):\n",
    "  df_partial = fit_all_data(filename=None, seasons=[input_index])\n",
    "  return df_partial\n",
    "\n",
    "if True: ## Change this to True to recalculate all the fits\n",
    "  processes_count = 4\n",
    "  processes_pool = Pool(processes_count)\n",
    "  dfs = processes_pool.map(run_job, range(4))\n",
    "  df = pd.concat(dfs)\n",
    "  df.to_hdf('~/analysis_final.h5','two_box_model')\n",
    "else:\n",
    "  df = pd.read_hdf(f'{path}/analysis_final.h5')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhtnUrf8o2YH"
   },
   "outputs": [],
   "source": [
    "# Calculate Q (the mixing parameter) as well\n",
    "df[\"Q\"] = (df[\"tl\"]* (df[\"ta\"] - df[\"tb\"]))/(df[\"ta\"]*df[\"tl\"] - df[\"tb\"]*df[\"tl\"] - df[\"ta\"]*df[\"tb\"] )\n",
    "df[\"tal\"] = 1/(1/df[\"tl\"] + 1/df[\"ta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yb52gU11-UOe"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,4, figsize=(15, 10))\n",
    "axs=axs.flatten()\n",
    "_=axs[0].hist(df[\"eta_max\"], bins=100)\n",
    "axs[0].set_xlabel(\"$\\eta_{max}$, median= %.3f\"%np.nanmedian(df[\"eta_max\"]))\n",
    "_=axs[1].hist(df[\"ta\"], bins=100)\n",
    "axs[1].set_xlabel(\"$\\\\tau_a$, months, median= %.1f\"%np.nanmedian(df[\"ta\"]))\n",
    "_=axs[2].hist(df[\"tl\"], bins=100, range=[0,250])\n",
    "axs[2].set_xlabel(\"$\\\\tau_\\ell$, months, median= %.1f\"%np.nanmedian(df[\"tl\"]))\n",
    "_=axs[3].hist(df[\"tb\"], bins=100, range=[0,500])\n",
    "axs[3].set_xlabel(\"$\\\\tau_b$, months, median= %.1f\"%np.nanmedian(df[\"tb\"]))\n",
    "_=axs[4].hist(df[\"dila\"], bins=100)\n",
    "axs[4].set_xlabel(\"$\\\\mu_a$, median= %.1f\"%np.nanmedian(df[\"dila\"]))\n",
    "_=axs[5].hist(df[\"dilb\"], bins=100)\n",
    "axs[5].set_xlabel(\"$\\\\mu_b$, median= %.1f\"%np.nanmedian(df[\"dilb\"]))\n",
    "_=axs[6].hist(df[\"err\"], bins=100)\n",
    "axs[6].set_xlabel(\"err, median= %.4f\"%np.nanmedian(df[\"err\"]))\n",
    "_=axs[7].hist(df[\"Q\"],bins=100,  label=\"Q mixing\")\n",
    "axs[7].set_xlabel(\"Q, median= %.4f\"%np.nanmedian(df[\"Q\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3pIQ1mkG-A1"
   },
   "source": [
    "# FIGURE 4: Latitudinal crossections of parameters $\\tau_a$,$\\tau_\\ell$,$\\tau_b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0h4g7LM_XGX"
   },
   "outputs": [],
   "source": [
    "xi = np.arange(-100,100,2)\n",
    "def geo_mean(x):\n",
    "  return np.exp(np.mean(np.log(x)))\n",
    "\n",
    "def average(xdata,ydata,xi,width=4):\n",
    "  result = []\n",
    "  for x in xi:\n",
    "    yd = geo_mean(ydata[(xdata > x-width//2) & (xdata < x+width//2)])\n",
    "    result.append(yd)\n",
    "  return np.array(result)\n",
    "\n",
    "fig, axs = plt.subplots(5,1, figsize=(4, 9.0),sharex=True)\n",
    "axs = axs.flatten()\n",
    "lati = np.linspace(-80,80,160)\n",
    "lat=df[\"lat\"]\n",
    "lng=df[\"lng\"]\n",
    "def scatter_and_line(ax, x,y, s=0.2, label=None):\n",
    "  _=ax.plot(lati, average(x,y,lati,width=10), label=label)\n",
    "  _=ax.scatter(x,y, s=s)\n",
    "\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"ta\"], label=\"Boreal winter\")\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"ta\"], label=\"Boreal summer\")\n",
    "axs[0].set_ylabel(\"$\\\\tau_a$  (months)\")\n",
    "\n",
    "scatter_and_line(axs[1], df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"tl\"], s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[1], df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"tl\"], s=0.2, label=\"Boreal summer\")\n",
    "axs[1].set_ylabel(\"$\\\\tau_\\ell$  (months)\")\n",
    "axs[1].set_yticks([10,20,30,40,50,100])\n",
    "\n",
    "scatter_and_line(axs[2], df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"tb\"], s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[2], df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"tb\"], s=0.2, label=\"Boreal summer\")\n",
    "axs[2].set_ylabel(\"$\\\\tau_b$  (months)\")\n",
    "axs[2].set_ylim(10,3000)\n",
    "#axs[2].set_yticks([1,3,10,20,30,40,50,100])\n",
    "\n",
    "scatter_and_line(axs[3],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"tb\"]/df[df[\"s\"]==0][\"ta\"], s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[3],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"tb\"]/df[df[\"s\"]==2][\"ta\"], s=0.2, label=\"Boreal summer\")\n",
    "axs[3].set_ylabel(\"$\\\\tau_b/\\\\tau_a$\")\n",
    "\n",
    "scatter_and_line(axs[4],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"ta\"]/df[df[\"s\"]==0][\"tl\"], s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[4],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"ta\"]/df[df[\"s\"]==2][\"tl\"], s=0.2, label=\"Boreal summer\")\n",
    "axs[4].set_ylabel(\"$\\\\tau_a/\\\\tau_\\ell$\")\n",
    "axs[4].set_ylim(0.03,10)\n",
    "\n",
    "axs[0].legend(loc = \"upper left\", bbox_to_anchor=(-0.03, 1.17, 1.0, 0.1), ncol=2)\n",
    "axs[-1].set_xlabel(\"latitude (deg)\")\n",
    "\n",
    "for i,ax in enumerate(axs[0:5]):\n",
    "  ax.set_yscale(\"log\")\n",
    "  ax.set_xticks([-75,-60,-45,-30,-15,0,15,30,45,60,75])\n",
    "  ax.set_xticklabels([\"‐75\",\"‐60\",\"‐45\",\"‐30\",\"‐15\",\"0\",\"15\",\"30\",\"45\",\"60\",\"75\"])\n",
    "  ax.yaxis.tick_right()\n",
    "  ax.yaxis.set_label_position(\"right\")\n",
    "  ax.text(-0.07,0.85,chr( ord('a')+i ), fontsize=14, weight='bold', transform=ax.transAxes)\n",
    "  ax.grid(which='major', axis='x', ls='dashed')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "fig.set_dpi(200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdMeFFwlM3TG"
   },
   "source": [
    "# FIGURE S6 Multifigure with individual fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WicmBPlrPANG"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2, figsize=(10, 12), sharex=True)\n",
    "i=0\n",
    "for y in range(axs.shape[0]):\n",
    "  for x in range(axs.shape[1]):\n",
    "    no_left  = x>0\n",
    "    no_right = x<(axs.shape[1]-1)\n",
    "    if i==0: plot_location(1, 0,   0, axs[y,x], no_left=no_left, no_right=no_right, label=\"Labrador sea\")         # a\n",
    "    if i==1: plot_location(1, 0,  42, axs[y,x], no_left=no_left, no_right=no_right, label=\"Norway\")               # b\n",
    "    if i==2: plot_location(1, 0,  63, axs[y,x], no_left=no_left, no_right=no_right, label=\"Newfoundland\")         # c\n",
    "    if i==3: plot_location(1, 0,  16, axs[y,x], no_left=no_left, no_right=no_right, label=\"North sea\")            # d\n",
    "    if i==4: plot_location(1, 0, 142, axs[y,x], no_left=no_left, no_right=no_right, label=\"Subtropical atlantic\") # e\n",
    "    if i==5: plot_location(1, 0, 137, axs[y,x], no_left=no_left, no_right=no_right, label=\"Subtropical atlantic\") # f\n",
    "    if i==6: plot_location(1, 0,  56, axs[y,x], no_left=no_left, no_right=no_right, label=\"Coast of Brazil\")      # g\n",
    "    if i==7: plot_location(1, 0, 129, axs[y,x], no_left=no_left, no_right=no_right, label=\"Equatorial Atlantic\")  # h\n",
    "    axs[y,x].text(0.02,0.9,chr(ord('a')+i), fontsize=14, weight='bold', transform=axs[y,x].transAxes)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIkIhu--b1R1"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2, figsize=(9, 12), sharex=True)\n",
    "i=0\n",
    "for y in range(axs.shape[0]):\n",
    "  for x in range(axs.shape[1]):\n",
    "    no_left  = x>0\n",
    "    no_right = x<(axs.shape[1]-1)\n",
    "    if i==0: plot_location(0, 0, 155, axs[y,x], no_left=no_left, no_right=no_right, label=\"Bering sea\")\n",
    "    if i==1: plot_location(0, 0,   7, axs[y,x], no_left=no_left, no_right=no_right, label=\"Hawaii\")\n",
    "    if i==2: plot_location(0, 0, 126, axs[y,x], no_left=no_left, no_right=no_right, label=\"Subtropical pacific\")\n",
    "    if i==3: plot_location(0, 2, 126, axs[y,x], no_left=no_left, no_right=no_right, label=\"Subtropical pacific\")\n",
    "    if i==4: plot_location(0, 0, 199, axs[y,x], no_left=no_left, no_right=no_right, label=\"Pacific Equatiorial\")\n",
    "    if i==5: plot_location(2, 0, 189, axs[y,x], no_left=no_left, no_right=no_right, label=\"Southern Ocean\")\n",
    "    if i==6: plot_location(2, 0,  13, axs[y,x], no_left=no_left, no_right=no_right, label=\"Kerguelen\")\n",
    "    if i==7: plot_location(3, 2,  33, axs[y,x], no_left=no_left, no_right=no_right, label=\"Ross sea\")\n",
    "    axs[y,x].text(0.02,0.9,chr(ord('i')+i), fontsize=14, weight='bold', transform=axs[y,x].transAxes)\n",
    "    i+=1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gajZwQna2cFw"
   },
   "source": [
    "# Plot the parameters on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtkrqLPq2geA"
   },
   "outputs": [],
   "source": [
    "def make_map_from_dataset(df):\n",
    "  names = [\"eta_max\", \"ta\", \"tl\", \"tb\", \"dila\", \"dilb\", \"err\", \"mean60\", \"stddev60\", \"mean180\", \"stddev180\", \"Q\"]\n",
    "  data_vars = dict([(name, ([\"season\", \"nlat\", \"nlon\"], np.full((4, *tlong.shape), np.nan))) for name in names])\n",
    "  data_vars[\"rsp\"] = ([\"season\", \"nlat\", \"nlon\"], np.full((4, *tlong.shape), np.nan))\n",
    "\n",
    "  for (r,s,p), row in df.iterrows():\n",
    "    polygon_masks = POLYGON_MASKS[r]\n",
    "    mask = polygon_masks[p]\n",
    "    index = np.where(mask > 0)\n",
    "    for name in names: data_vars[name][1][s,:,:][index] = (mask * row[name])[index]\n",
    "    data_vars[\"rsp\"][1][s,:,:][index] = (mask * (r*1E6+s*1E5+p))[index]\n",
    "\n",
    "  # form a dataset\n",
    "  whole_ds = xr.Dataset(\n",
    "    data_vars = data_vars,\n",
    "    coords=dict(\n",
    "        TLONG=([\"nlat\", \"nlon\"], tlong),\n",
    "        TLAT=([\"nlat\", \"nlon\"], tlat),\n",
    "    ),\n",
    "  )\n",
    "  whole_ds['season'] = ['January', 'April', 'July', 'October']\n",
    "  return whole_ds\n",
    "whole_ds = make_map_from_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4kwz-Pu9eos"
   },
   "outputs": [],
   "source": [
    "def plot_mapped_data(whole_ds, name, lims, title=\"title\", single_panel=False, cmap_label=\"rainbow\"):\n",
    "  FONTSIZE = 13\n",
    "  def modify(ax):\n",
    "    # label the cells\n",
    "    for (r,p),pd  in polygon_mask_map.items():\n",
    "      lat,lng = pd[\"mean_latlng\"]\n",
    "      lng = lng - central_longitude\n",
    "      if lng < -180: lng += 360\n",
    "      ax.text(lng,lat, f'{p}', rotation='horizontal',\n",
    "              va='center', ha='center', fontsize=FONTSIZE-8)\n",
    "    ax.set_extent([00, 360, -80, 80], crs=ccrs.PlateCarree())\n",
    "    ax.stock_img()\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "  central_longitude=260\n",
    "  seasons=4\n",
    "  if single_panel: seasons=1\n",
    "  gridsize = 1 if single_panel else 2\n",
    "  titles = [\"$\\\\tau_{loss}$\", \"ML depth\",\"Deep Reservoir depth\"]\n",
    "  fig = plt.figure(figsize=(10*gridsize,8.7/2.0*gridsize))\n",
    "  axs=[]\n",
    "  for j in range(seasons):\n",
    "        ax = fig.add_subplot(gridsize, gridsize, j+1, projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "        ax.pcolormesh(whole_ds.TLONG, whole_ds.TLAT, whole_ds.isel(season=j)[name],\n",
    "                          transform=ccrs.PlateCarree(), cmap=cmap_label, vmin=lims[0], vmax=lims[1])\n",
    "\n",
    "        if j < 2:\n",
    "          ax.set_title(title, loc='center', fontsize=FONTSIZE+2)\n",
    "        if j%2 == 0:\n",
    "            ax.set_yticks(np.arange(-60, 80, 30), crs=ccrs.PlateCarree())\n",
    "            ax.set_yticklabels(ax.get_yticks(), fontsize=FONTSIZE)\n",
    "        if j>=2:\n",
    "          ax.set_xticks(np.arange(0, 360, 60), crs=ccrs.PlateCarree())\n",
    "          ax.set_xticklabels(ax.get_xticks(), fontsize=FONTSIZE)\n",
    "\n",
    "        if not single_panel:\n",
    "          ax.text(0, 70, f'{whole_ds.season.values[j]}', rotation='horizontal', va='center', ha='center', fontsize=FONTSIZE)\n",
    "        modify(ax)\n",
    "        axs.append(ax)\n",
    "  return fig, axs\n",
    "\n",
    "  def add_colorbar(x0, y0, vmin, vmax, label, cmap_label=\"rainbow\"):\n",
    "    '''\n",
    "    x0, y0: start location for the colorbar\n",
    "    vmin, vmax: range of the colorbar\n",
    "    label: label of the colorbar'\n",
    "    '''\n",
    "    cax = fig.add_axes([x0, y0, 0.2, 0.03])  # [x0, y0, width, height]\n",
    "    cmap = plt.colormaps[cmap_label]\n",
    "    normalize = plt.Normalize(vmin=vmin, vmax=vmax)  # Normalize the color values\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=normalize)\n",
    "    cbar = fig.colorbar(sm, cax=cax, shrink=0.9, label=label, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=FONTSIZE)\n",
    "\n",
    "  add_colorbar(0.15, 0.05, lims[0], lims[1], name, cmap_label)\n",
    "  plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od5AfcdCVhbL"
   },
   "source": [
    "# FIGURE1 Part 1:  Mean eta and variance at 5 and 15 yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-69h4taVquo"
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "def plot_4panels(whole_ds, data_array, lims, cmap, datascale=\"linear\", title=\"title\", figscale=1.0):\n",
    "  FONTSIZE = 13\n",
    "  def modify(ax, numbers=False):\n",
    "    # label the cells\n",
    "    if numbers:\n",
    "     for (r,p),pd  in polygon_mask_map.items():\n",
    "      lat,lng = pd[\"mean_latlng\"]\n",
    "      lng = lng - central_longitude\n",
    "      if lng < -180: lng += 360\n",
    "      ax.text(lng,lat, f'{p}', rotation='horizontal',\n",
    "              va='center', ha='center', fontsize=FONTSIZE-8)\n",
    "    ax.set_extent([00, 360, -80, 80], crs=ccrs.PlateCarree())\n",
    "    ax.imshow(imread('./lightearth.jpg'),\n",
    "              origin='upper', transform=ccrs.PlateCarree(),\n",
    "              extent=[-180, 180, -90, 90])\n",
    "\n",
    "    #ax.stock_img()\n",
    "    #ax.coastlines()\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "  central_longitude=260\n",
    "\n",
    "  gridsize = 2\n",
    "  fig = plt.figure(figsize=(figscale*10*gridsize,figscale*8.7/2.0*gridsize))\n",
    "  fig.set_dpi(200)\n",
    "\n",
    "  for j in range(len(data_array)):\n",
    "        ax = fig.add_subplot(gridsize, gridsize, j+1, projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "        ax.pcolormesh(whole_ds.TLONG, whole_ds.TLAT,\n",
    "                      np.log10(data_array[j]) if datascale == \"log10\" else data_array[j],\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap[j], vmin=lims[j][0], vmax=lims[j][1])\n",
    "\n",
    "        if j%2 == 0:\n",
    "            ax.set_yticks(np.arange(-60, 80, 30), crs=ccrs.PlateCarree())\n",
    "            ax.set_yticklabels(ax.get_yticks(), fontsize=FONTSIZE)\n",
    "        if j>=2:\n",
    "          ax.set_xticks(np.arange(0, 360, 60), crs=ccrs.PlateCarree())\n",
    "          ax.set_xticklabels(ax.get_xticks(), fontsize=FONTSIZE)\n",
    "\n",
    "        #ax.text(0, 70, title[j], rotation='horizontal', va='center', ha='center', fontsize=FONTSIZE)\n",
    "        ax.text(-140, 70, title[j], rotation='horizontal', va='center', ha='left', fontsize=FONTSIZE)\n",
    "        ax.text(0.02,0.9,['a','b','c','d'][j], fontsize=14, weight='bold', transform=ax.transAxes)\n",
    "        modify(ax)\n",
    "\n",
    "\n",
    "  def add_colorbar(x0, y0, vmin, vmax, label, cmap):\n",
    "    '''\n",
    "    x0, y0: start location for the colorbar\n",
    "    vmin, vmax: range of the colorbars[0]\n",
    "    label: label of the colorbar'\n",
    "    '''\n",
    "    cax = fig.add_axes([x0, y0, 0.32, 0.03])  # [x0, y0, width, height]\n",
    "    cmap = cmap\n",
    "    normalize = plt.Normalize(vmin=vmin, vmax=vmax)  # Normalize the color values\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=normalize)\n",
    "    cbar = fig.colorbar(sm, cax=cax, shrink=0.9, orientation='horizontal')\n",
    "    cbar.set_label(label=label, size=FONTSIZE)\n",
    "    cbar.ax.tick_params(labelsize=FONTSIZE)\n",
    "\n",
    "  add_colorbar(0.16, 0.00, lims[0][0], lims[0][1], \"Mean($\\eta$)\", cmap[0])\n",
    "  add_colorbar(0.55, 0.00, lims[1][0], lims[1][1], \"Stddev($\\eta$)\", cmap[1])\n",
    "  plt.subplots_adjust(wspace=0.01, hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lf1hZ0C5Ea4r"
   },
   "outputs": [],
   "source": [
    "plot_4panels(whole_ds, [whole_ds.isel(season=0)[\"mean60\"],\n",
    "                        whole_ds.isel(season=0)[\"stddev60\"],\n",
    "                        whole_ds.isel(season=0)[\"mean180\"],\n",
    "                        whole_ds.isel(season=0)[\"stddev180\"]],\n",
    "                        [(0.3,0.9),(0,0.1),\n",
    "                         (0.3,0.9),(0,0.1)],\n",
    "             cmap = [cm.get_cmap('rainbow'),\n",
    "                     plt.colormaps[\"viridis\"],\n",
    "                     cm.get_cmap('rainbow'),\n",
    "                     plt.colormaps[\"viridis\"]],\n",
    "             title=[\"Mean($\\eta$) at 5 yrs\",\n",
    "                    \"Stddev($\\eta$) at 5 yrs\",\n",
    "                    \"Mean($\\eta$) at 15 yrs\",\n",
    "                    \"Stddev($\\eta$) at 15 yrs\"],\n",
    "             figscale=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5Ud6zMUrXeB"
   },
   "source": [
    "# FIGURE  1 Part 2: Cross sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTsybQlNc34_"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(10, 2.5), sharey=True)\n",
    "axs = axs.flatten()\n",
    "lati = np.linspace(-80,80,160)\n",
    "lat=df[\"lat\"]\n",
    "lng=df[\"lng\"]\n",
    "\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta24\"],  s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta24\"],  s=0.2, label=\"Boreal summer\")\n",
    "\n",
    "scatter_and_line(axs[1],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta60\"],  s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[1],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta60\"],  s=0.2, label=\"Boreal summer\")\n",
    "\n",
    "scatter_and_line(axs[2],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta180\"], s=0.2, label=\"Boreal winter\")\n",
    "scatter_and_line(axs[2],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta180\"], s=0.2, label=\"Boreal summer\")\n",
    "\n",
    "axs[0].set_ylabel(\"$\\eta(t)$\")\n",
    "axs[2].legend(bbox_to_anchor=(0.5,0.5))\n",
    "for i,ax in enumerate(axs):\n",
    "  ax.set_xticks([-75,-60,-45,-30,-15,0,15,30,45,60,75])\n",
    "  ax.set_xticklabels([\"‐75\",\"‐60\",\"‐45\",\"‐30\",\"‐15\",\"0\",\"15\",\"30\",\"45\",\"60\",\"75\"])\n",
    "  ax.text(0.02,1.05,['e','f','g'][i], fontsize=14, weight='bold', transform=ax.transAxes)\n",
    "  ax.set_title(\"After %s years\"%([2,5,15][i]), y=0.16, pad=-14)\n",
    "  ax.grid()\n",
    "  ax.set_xlabel(\"lat\")\n",
    "  ax.set_ylim(0.0,0.9)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.set_dpi(200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUScw4fBtgmx"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8, 3.0),sharey=True)\n",
    "axs = axs.flatten()\n",
    "lati = np.linspace(-80,80,160)\n",
    "lat=df[\"lat\"]\n",
    "lng=df[\"lng\"]\n",
    "\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta24\"],  s=0.2, label=\"$\\eta$ after 2yrs\")\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta60\"],  s=0.2, label=\"$\\eta$ after 5yrs\")\n",
    "scatter_and_line(axs[0],df[df[\"s\"]==0][\"lat\"], df[df[\"s\"]==0][\"eta180\"], s=0.2, label=\"$\\eta$ after 15yrs\")\n",
    "axs[0].set_ylabel(\"Mean($\\eta$) after 5yrs\")\n",
    "\n",
    "scatter_and_line(axs[1],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta24\"],  s=0.2, label=\"$\\eta$ after 2yrs\")\n",
    "scatter_and_line(axs[1],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta60\"],  s=0.2, label=\"$\\eta$ after 5yrs\")\n",
    "scatter_and_line(axs[1],df[df[\"s\"]==2][\"lat\"], df[df[\"s\"]==2][\"eta180\"], s=0.2, label=\"$\\eta$ after 15yrs\")\n",
    "axs[0].set_ylabel(\"Mean($\\eta$) after 15yrs\")\n",
    "\n",
    "axs[1].yaxis.tick_right()\n",
    "axs[1].yaxis.set_label_position(\"right\")\n",
    "\n",
    "axs[1].legend(loc = \"lower right\")\n",
    "axs[0].set_xlabel(\"lat\")\n",
    "axs[1].set_xlabel(\"lat\")\n",
    "for ax in axs:\n",
    "  #ax.set_yscale(\"log\")\n",
    "  ax.set_xticks([-75,-60,-45,-30,-15,0,15,30,45,60,75])\n",
    "  ax.set_xticklabels([\"‐75\",\"‐60\",\"‐45\",\"‐30\",\"‐15\",\"0\",\"15\",\"30\",\"45\",\"60\",\"75\"])\n",
    "\n",
    "axs[0].text(0.02,0.9,'a', fontsize=14, weight='bold', transform=axs[0].transAxes)\n",
    "axs[1].text(0.02,0.9,'b', fontsize=14, weight='bold', transform=axs[1].transAxes)\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Do a seperate plot just for coastal locations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9GBba8XA3Yt"
   },
   "outputs": [],
   "source": [
    "def plot_4panels_logscale(whole_ds, data_array, lims, cmap, title=\"title\", figscale=1.0):\n",
    "  FONTSIZE = 13\n",
    "  def modify(ax, numbers=False):\n",
    "    # label the cells\n",
    "    if numbers:\n",
    "     for (r,p),pd  in polygon_mask_map.items():\n",
    "      lat,lng = pd[\"mean_latlng\"]\n",
    "      lng = lng - central_longitude\n",
    "      if lng < -180: lng += 360\n",
    "      ax.text(lng,lat, f'{p}', rotation='horizontal',\n",
    "              va='center', ha='center', fontsize=FONTSIZE-8)\n",
    "    ax.set_extent([00, 360, -80, 80], crs=ccrs.PlateCarree())\n",
    "    ax.imshow(imread('./lightearth.jpg'),\n",
    "              origin='upper', transform=ccrs.PlateCarree(),\n",
    "              extent=[-180, 180, -90, 90])\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "  central_longitude=260\n",
    "\n",
    "  gridsize = 2\n",
    "  fig = plt.figure(figsize=(figscale*10*gridsize,figscale*8.7/2.0*gridsize))\n",
    "  fig.set_dpi(200)\n",
    "\n",
    "  for j in range(len(data_array)):\n",
    "        ax = fig.add_subplot(gridsize, gridsize, j+1, projection=ccrs.PlateCarree(central_longitude=central_longitude))\n",
    "        ax.pcolormesh(whole_ds.TLONG, whole_ds.TLAT,\n",
    "                      np.log10(data_array[j]),\n",
    "                      transform=ccrs.PlateCarree(), cmap=cmap[j], vmin=np.log10(lims[j][0]), vmax=np.log10(lims[j][1]) )\n",
    "\n",
    "        if j%2 == 0:\n",
    "            ax.set_yticks(np.arange(-60, 80, 30), crs=ccrs.PlateCarree())\n",
    "            ax.set_yticklabels(ax.get_yticks(), fontsize=FONTSIZE)\n",
    "        if j>=2:\n",
    "          ax.set_xticks(np.arange(0, 360, 60), crs=ccrs.PlateCarree())\n",
    "          ax.set_xticklabels(ax.get_xticks(), fontsize=FONTSIZE)\n",
    "\n",
    "        ax.text(-140, 70, title[j], rotation='horizontal', va='center', ha='left', fontsize=FONTSIZE)\n",
    "        ax.text(0.02,0.9,['a','b','c','d'][j], fontsize=14, weight='bold', transform=ax.transAxes)\n",
    "        modify(ax)\n",
    "\n",
    "\n",
    "  def add_colorbar(x0, y0, vmin, vmax, label, cmap):\n",
    "    '''\n",
    "    x0, y0: start location for the colorbar\n",
    "    vmin, vmax: range of the colorbars[0]\n",
    "    label: label of the colorbar'\n",
    "    '''\n",
    "    cax = fig.add_axes([x0, y0, 0.62, 0.03])  # [x0, y0, width, height]\n",
    "    cmap = cmap\n",
    "    normalize = plt.Normalize(vmin=np.log10(vmin), vmax=np.log10(vmax) )  # Normalize the color values\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=normalize)\n",
    "    cbar = fig.colorbar(sm, cax=cax, shrink=0.9, orientation='horizontal')\n",
    "    cbar.set_label(label=label, size=FONTSIZE)\n",
    "    cbar.ax.tick_params(labelsize=FONTSIZE)\n",
    "\n",
    "    ticks = [0.1,0.3,1,3,10,30,100,300,1000,3000,10000]\n",
    "    cbar.ax.set_xticks([np.log10(t) for t in ticks if (t>=vmin and t<=vmax) ])\n",
    "    cbar.ax.set_xticklabels([t for t in ticks if (t>=vmin and t<=vmax) ])\n",
    "\n",
    "  add_colorbar(0.16, 0.00, lims[0][0], lims[0][1], \"time (months)\", cmap[0])\n",
    "  plt.subplots_adjust(wspace=0.01, hspace=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vz7--jSNQAYG"
   },
   "outputs": [],
   "source": [
    "plot_4panels_logscale(whole_ds, [whole_ds.isel(season=i)[\"ta\"] for i in range(0,4)],\n",
    "                      [(3,100)]*4,\n",
    "             cmap = [cm.get_cmap('rainbow')]*4,\n",
    "             title=[\"$\\\\tau_a$ January Release\",\n",
    "                    \"$\\\\tau_a$ April Release\",\n",
    "                    \"$\\\\tau_a$ July Release\",\n",
    "                    \"$\\\\tau_a$ October Release\"],\n",
    "             figscale=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLeLUU2JTvBE"
   },
   "outputs": [],
   "source": [
    "plot_4panels_logscale(whole_ds, [whole_ds.isel(season=i)[\"tl\"] for i in range(0,4)],\n",
    "                      [(3,301)]*4,\n",
    "             cmap = [cm.get_cmap('rainbow')]*4,\n",
    "             title=[\"$\\\\tau_\\ell$ January Release\",\n",
    "                    \"$\\\\tau_\\ell$ April Release\",\n",
    "                    \"$\\\\tau_\\ell$ July Release\",\n",
    "                    \"$\\\\tau_\\ell$ October Release\"],\n",
    "             figscale=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_XJKPpvUDUE"
   },
   "outputs": [],
   "source": [
    "plot_4panels_logscale(whole_ds, [whole_ds.isel(season=i)[\"tb\"] for i in range(0,4)],\n",
    "                      [(3,10001)]*4,\n",
    "             cmap = [cm.get_cmap('rainbow')]*4,\n",
    "             title=[\"$\\\\tau_b$ January Release\",\n",
    "                    \"$\\\\tau_b$ April Release\",\n",
    "                    \"$\\\\tau_b$ July Release\",\n",
    "                    \"$\\\\tau_b$ October Release\"],\n",
    "             figscale=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi_Lt_Ew_Me_"
   },
   "outputs": [],
   "source": [
    "plot_4panels(whole_ds, [whole_ds.isel(season=i)[\"eta_max\"] for i in range(0,4)],\n",
    "                      [(0.70,1.0)]*4,\n",
    "             cmap = [cm.get_cmap('rainbow')]*4,\n",
    "             title=[\"$\\eta_{max}$ January Release\",\n",
    "                    \"$\\eta_{max}$ April Release\",\n",
    "                    \"$\\eta_{max}$ July Release\",\n",
    "                    \"$\\eta_{max}$ October Release\"],\n",
    "             figscale=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P-pEsQWb5mi"
   },
   "outputs": [],
   "source": [
    "plot_4panels(whole_ds, [whole_ds.isel(season=i)[\"err\"] for i in range(0,4)],\n",
    "                      [(0.0,0.1)]*4,\n",
    "             cmap = [cm.get_cmap('rainbow')]*4,\n",
    "             title=[\"Residual error, January\",\n",
    "                    \"Residual error, April\",\n",
    "                    \"Residual error, July\",\n",
    "                    \"Residual error, October\"],\n",
    "             figscale=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDgwTjdObOhz"
   },
   "source": [
    "# Examples of complex alkalinity dynamics beyond this model\n",
    "\n",
    "These location have some residual fitting error (See map above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOKtGnR-Ofru"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,2, figsize=(9, 18), sharex=True)\n",
    "i=0\n",
    "for y in range(axs.shape[0]):\n",
    "  for x in range(axs.shape[1]):\n",
    "    no_left  = x>0\n",
    "    no_right = x<(axs.shape[1]-1)\n",
    "    if i==0: plot_location(0, 0, 126, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #q\n",
    "    if i==1: plot_location(2, 1, 225, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #r\n",
    "    if i==2: plot_location(2, 0, 225, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #s\n",
    "    if i==3: plot_location(0, 2,  34, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #t\n",
    "    if i==4: plot_location(0, 0, 178, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #u\n",
    "    if i==5: plot_location(0, 3, 156, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #v\n",
    "    if i==6: plot_location(0, 3,  83, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #w\n",
    "    if i==7: plot_location(0, 2,  83, axs[y,x], no_left=no_left, no_right=no_right, label=\"\")  #x\n",
    "    if i==8:  plot_location(0, 1, 83,  axs[y,x], no_left=no_left, no_right=no_right, label=\"\") #y\n",
    "    if i==9:  plot_location(0, 2, 161, axs[y,x], no_left=no_left, no_right=no_right, label=\"\") #z\n",
    "    if i==10: plot_location(1, 2, 128, axs[y,x], no_left=no_left, no_right=no_right, label=\"\") #aa\n",
    "    if i==11: plot_location(2, 0, 200, axs[y,x], no_left=no_left, no_right=no_right, label=\"\") #ab\n",
    "\n",
    "    axs[y,x].text(0.02,0.9,chr(ord('q')+i), fontsize=14, weight='bold', transform=axs[y,x].transAxes)\n",
    "    i+=1\n",
    "\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
